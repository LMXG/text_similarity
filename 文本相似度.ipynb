{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -oq /home/aistudio/data/data52714/bq_corpus.zip -d data/\n",
    "!unzip -oq /home/aistudio/data/data52714/paws-x-zh.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/da/77/364cd13f3488bc22297f5e07be2a1faf04f939844a3ea3fd84e3ab79489f/paddlenlp-2.1.1-py3-none-any.whl (735kB)\n",
      "\u001b[K     |████████████████████████████████| 737kB 15.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Collecting paddlefsl==1.0.0 (from paddlenlp)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/5d/65/9970dd09309eb673303206befc9f2fdc9c2d29d31f002ae8d6c7b442f562/paddlefsl-1.0.0-py3-none-any.whl (55kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 13.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Collecting requests~=2.24.0 (from paddlefsl==1.0.0->paddlenlp)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 16.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow==8.2.0 (from paddlefsl==1.0.0->paddlenlp)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/33/34/542152297dcc6c47a9dcb0685eac6d652d878ed3cea83bf2b23cb988e857/Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 15.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm~=4.27.0 (from paddlefsl==1.0.0->paddlenlp)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/16/33/6d8bd6a7c4238f383426b7593bf05bfd6d9e1f10c3084b56c0f14d973754/tqdm-4.27.0-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 22.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (3.0.4)\n",
      "\u001b[31mERROR: blackhole 1.0.1 has requirement numpy<=1.19.5, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: paddlefsl 1.0.0 has requirement numpy~=1.19.2, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: requests, pillow, tqdm, paddlefsl, paddlenlp\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Found existing installation: Pillow 7.1.2\n",
      "    Uninstalling Pillow-7.1.2:\n",
      "      Successfully uninstalled Pillow-7.1.2\n",
      "  Found existing installation: tqdm 4.36.1\n",
      "    Uninstalling tqdm-4.36.1:\n",
      "      Successfully uninstalled tqdm-4.36.1\n",
      "  Found existing installation: paddlenlp 2.0.7\n",
      "    Uninstalling paddlenlp-2.0.7:\n",
      "      Successfully uninstalled paddlenlp-2.0.7\n",
      "Successfully installed paddlefsl-1.0.0 paddlenlp-2.1.1 pillow-8.2.0 requests-2.24.0 tqdm-4.27.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp -i https://mirror.baidu.com/pypi/simple  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "from paddlenlp.datasets import load_dataset\n",
    "import paddlenlp\n",
    "from data import convert_example, create_dataloader, load_my_dataset\n",
    "from model import PointwiseMatching\n",
    "from train import train_model\n",
    "from utils import predict, write_tsv\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6827/6827 [00:00<00:00, 60732.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset length: 238766\n",
      "dev dataset length: 8802\n"
     ]
    }
   ],
   "source": [
    "train_ds, dev_ds = load_dataset(\"lcqmc\", splits=[\"train\", \"dev\"])\n",
    "print(\"train dataset length:\", len(train_ds))\n",
    "print(\"dev dataset length:\", len(dev_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 定义样本转换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-17 08:50:14,254] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-gram-zh\n",
      "[2021-11-17 08:50:14,257] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/vocab.txt\n",
      "100%|██████████| 78/78 [00:00<00:00, 2026.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# 因为是基于预训练模型 ERNIE-Gram 来进行，所以需要首先加载 ERNIE-Gram 的 tokenizer，\n",
    "# 后续样本转换函数基于 tokenizer 对文本进行切分\n",
    "\n",
    "tokenizer = paddlenlp.transformers.ErnieGramTokenizer.from_pretrained('ernie-gram-zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练集和验证集的样本转换函数\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 定义 Dataloader\n",
    "下面我们基于组 batchify_fn 函数和样本转换函数 trans_func 来构造训练集的 DataLoader, 支持多卡训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataloader length: 1866\n",
      "dev dataloader length: 69\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_data_loader = create_dataloader(dataset=train_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='train',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "dev_data_loader = create_dataloader(dataset=dev_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='dev',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "print(\"train dataloader length:\", len(train_data_loader))\n",
    "print(\"dev dataloader length:\", len(dev_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-17 08:50:42,034] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/ernie_gram_zh.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-gram-zh\n",
      "[2021-11-17 08:50:42,036] [    INFO] - Downloading ernie_gram_zh.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/ernie_gram_zh.pdparams\n",
      "100%|██████████| 583566/583566 [00:09<00:00, 64544.47it/s]\n",
      "W1117 08:50:51.253046   104 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1117 08:50:51.257918   104 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "# 我们基于 ERNIE-Gram 模型结构搭建 Point-wise 语义匹配网络\n",
    "# 所以此处先定义 ERNIE-Gram 的 pretrained_model\n",
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "# 定义 Point-wise 语义匹配网络\n",
    "model = PointwiseMatching(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "epochs = 6\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate=5E-5, total_steps=num_training_steps, warmup=0.15)\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=5e-4,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.49566, accu: 0.72344, lr: 0.0000043, speed: 2.63 step/s\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.45019, accu: 0.73523, lr: 0.0000046, speed: 2.34 step/s\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.40357, accu: 0.74171, lr: 0.0000049, speed: 2.41 step/s\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.37280, accu: 0.75094, lr: 0.0000052, speed: 2.38 step/s\n",
      "global step 50, epoch: 1, batch: 50, loss: 0.31138, accu: 0.76158, lr: 0.0000055, speed: 2.27 step/s\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.47690, accu: 0.77023, lr: 0.0000058, speed: 2.37 step/s\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.40897, accu: 0.78028, lr: 0.0000061, speed: 2.37 step/s\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.40201, accu: 0.78580, lr: 0.0000064, speed: 2.39 step/s\n",
      "global step 90, epoch: 1, batch: 90, loss: 0.34516, accu: 0.79219, lr: 0.0000067, speed: 2.36 step/s\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.28976, accu: 0.79832, lr: 0.0000070, speed: 2.38 step/s\n",
      "eval dev loss: 0.63585, accu: 0.78528\n",
      "global step 110, epoch: 1, batch: 110, loss: 0.27124, accu: 0.87031, lr: 0.0000073, speed: 0.63 step/s\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.36997, accu: 0.86602, lr: 0.0000076, speed: 2.33 step/s\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.36552, accu: 0.86953, lr: 0.0000079, speed: 2.17 step/s\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.26383, accu: 0.87187, lr: 0.0000082, speed: 2.24 step/s\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.43707, accu: 0.87500, lr: 0.0000085, speed: 2.35 step/s\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.32505, accu: 0.87344, lr: 0.0000088, speed: 2.35 step/s\n",
      "global step 170, epoch: 1, batch: 170, loss: 0.30450, accu: 0.87288, lr: 0.0000091, speed: 2.13 step/s\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.21678, accu: 0.87305, lr: 0.0000094, speed: 2.32 step/s\n",
      "global step 190, epoch: 1, batch: 190, loss: 0.33067, accu: 0.87300, lr: 0.0000096, speed: 2.48 step/s\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.24051, accu: 0.87328, lr: 0.0000099, speed: 2.29 step/s\n",
      "eval dev loss: 0.41287, accu: 0.84776\n",
      "global step 210, epoch: 1, batch: 210, loss: 0.29491, accu: 0.88203, lr: 0.0000102, speed: 0.63 step/s\n",
      "global step 220, epoch: 1, batch: 220, loss: 0.24580, accu: 0.88516, lr: 0.0000105, speed: 2.61 step/s\n",
      "global step 230, epoch: 1, batch: 230, loss: 0.27993, accu: 0.88984, lr: 0.0000108, speed: 2.36 step/s\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.21785, accu: 0.89316, lr: 0.0000111, speed: 2.42 step/s\n",
      "global step 250, epoch: 1, batch: 250, loss: 0.21420, accu: 0.89172, lr: 0.0000114, speed: 2.47 step/s\n",
      "global step 260, epoch: 1, batch: 260, loss: 0.33307, accu: 0.88932, lr: 0.0000117, speed: 2.45 step/s\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.30009, accu: 0.88884, lr: 0.0000120, speed: 2.12 step/s\n",
      "global step 280, epoch: 1, batch: 280, loss: 0.19113, accu: 0.89023, lr: 0.0000123, speed: 2.40 step/s\n",
      "global step 290, epoch: 1, batch: 290, loss: 0.25309, accu: 0.89010, lr: 0.0000126, speed: 2.16 step/s\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.23261, accu: 0.89156, lr: 0.0000129, speed: 2.29 step/s\n",
      "eval dev loss: 0.36631, accu: 0.85901\n",
      "global step 310, epoch: 1, batch: 310, loss: 0.30941, accu: 0.89297, lr: 0.0000132, speed: 0.62 step/s\n",
      "global step 320, epoch: 1, batch: 320, loss: 0.18963, accu: 0.89180, lr: 0.0000135, speed: 2.32 step/s\n",
      "global step 330, epoch: 1, batch: 330, loss: 0.31671, accu: 0.89141, lr: 0.0000138, speed: 2.33 step/s\n",
      "global step 340, epoch: 1, batch: 340, loss: 0.20531, accu: 0.88984, lr: 0.0000141, speed: 2.40 step/s\n",
      "global step 350, epoch: 1, batch: 350, loss: 0.25791, accu: 0.89203, lr: 0.0000144, speed: 2.32 step/s\n",
      "global step 360, epoch: 1, batch: 360, loss: 0.33180, accu: 0.89193, lr: 0.0000147, speed: 2.32 step/s\n",
      "global step 370, epoch: 1, batch: 370, loss: 0.21115, accu: 0.89163, lr: 0.0000150, speed: 2.31 step/s\n",
      "global step 380, epoch: 1, batch: 380, loss: 0.25567, accu: 0.89023, lr: 0.0000153, speed: 2.36 step/s\n",
      "global step 390, epoch: 1, batch: 390, loss: 0.26144, accu: 0.89115, lr: 0.0000156, speed: 2.09 step/s\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.24247, accu: 0.89125, lr: 0.0000159, speed: 2.28 step/s\n",
      "eval dev loss: 0.33717, accu: 0.86923\n",
      "global step 410, epoch: 1, batch: 410, loss: 0.11627, accu: 0.89609, lr: 0.0000162, speed: 0.63 step/s\n",
      "global step 420, epoch: 1, batch: 420, loss: 0.17502, accu: 0.90195, lr: 0.0000165, speed: 2.35 step/s\n",
      "global step 430, epoch: 1, batch: 430, loss: 0.23066, accu: 0.89922, lr: 0.0000168, speed: 2.35 step/s\n",
      "global step 440, epoch: 1, batch: 440, loss: 0.26045, accu: 0.90000, lr: 0.0000171, speed: 2.36 step/s\n",
      "global step 450, epoch: 1, batch: 450, loss: 0.19620, accu: 0.89781, lr: 0.0000174, speed: 2.31 step/s\n",
      "global step 460, epoch: 1, batch: 460, loss: 0.18064, accu: 0.89857, lr: 0.0000177, speed: 2.38 step/s\n",
      "global step 470, epoch: 1, batch: 470, loss: 0.27598, accu: 0.90022, lr: 0.0000180, speed: 2.32 step/s\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.31156, accu: 0.90148, lr: 0.0000189, speed: 2.33 step/s\n",
      "eval dev loss: 0.34561, accu: 0.86969\n",
      "global step 510, epoch: 1, batch: 510, loss: 0.31254, accu: 0.90703, lr: 0.0000192, speed: 0.63 step/s\n",
      "global step 520, epoch: 1, batch: 520, loss: 0.20604, accu: 0.90000, lr: 0.0000195, speed: 2.25 step/s\n",
      "global step 530, epoch: 1, batch: 530, loss: 0.27525, accu: 0.89844, lr: 0.0000198, speed: 2.44 step/s\n",
      "global step 540, epoch: 1, batch: 540, loss: 0.30493, accu: 0.90156, lr: 0.0000201, speed: 2.21 step/s\n",
      "global step 550, epoch: 1, batch: 550, loss: 0.23634, accu: 0.89922, lr: 0.0000204, speed: 2.23 step/s\n",
      "global step 560, epoch: 1, batch: 560, loss: 0.29422, accu: 0.89961, lr: 0.0000207, speed: 2.27 step/s\n",
      "global step 570, epoch: 1, batch: 570, loss: 0.29142, accu: 0.89844, lr: 0.0000210, speed: 2.30 step/s\n",
      "global step 580, epoch: 1, batch: 580, loss: 0.26392, accu: 0.89912, lr: 0.0000213, speed: 2.33 step/s\n",
      "global step 590, epoch: 1, batch: 590, loss: 0.22124, accu: 0.89974, lr: 0.0000216, speed: 2.37 step/s\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.24210, accu: 0.89805, lr: 0.0000219, speed: 2.32 step/s\n",
      "eval dev loss: 0.41587, accu: 0.82913\n",
      "global step 610, epoch: 1, batch: 610, loss: 0.20372, accu: 0.89297, lr: 0.0000222, speed: 0.69 step/s\n",
      "global step 620, epoch: 1, batch: 620, loss: 0.13557, accu: 0.90273, lr: 0.0000225, speed: 2.43 step/s\n",
      "global step 630, epoch: 1, batch: 630, loss: 0.24396, accu: 0.89896, lr: 0.0000228, speed: 2.42 step/s\n",
      "global step 640, epoch: 1, batch: 640, loss: 0.21029, accu: 0.90078, lr: 0.0000230, speed: 2.25 step/s\n",
      "global step 650, epoch: 1, batch: 650, loss: 0.34051, accu: 0.90203, lr: 0.0000233, speed: 2.38 step/s\n",
      "global step 660, epoch: 1, batch: 660, loss: 0.21011, accu: 0.90456, lr: 0.0000236, speed: 2.32 step/s\n",
      "global step 670, epoch: 1, batch: 670, loss: 0.17871, accu: 0.90446, lr: 0.0000239, speed: 2.20 step/s\n",
      "global step 680, epoch: 1, batch: 680, loss: 0.26430, accu: 0.90400, lr: 0.0000242, speed: 2.28 step/s\n",
      "global step 690, epoch: 1, batch: 690, loss: 0.24654, accu: 0.90408, lr: 0.0000245, speed: 2.20 step/s\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.24741, accu: 0.90242, lr: 0.0000248, speed: 2.24 step/s\n",
      "eval dev loss: 0.35337, accu: 0.85753\n",
      "global step 710, epoch: 1, batch: 710, loss: 0.25816, accu: 0.90312, lr: 0.0000251, speed: 0.69 step/s\n",
      "global step 720, epoch: 1, batch: 720, loss: 0.19631, accu: 0.90469, lr: 0.0000254, speed: 2.18 step/s\n",
      "global step 730, epoch: 1, batch: 730, loss: 0.20410, accu: 0.90365, lr: 0.0000257, speed: 2.32 step/s\n",
      "global step 760, epoch: 1, batch: 760, loss: 0.24541, accu: 0.90638, lr: 0.0000266, speed: 2.31 step/s\n",
      "global step 770, epoch: 1, batch: 770, loss: 0.24840, accu: 0.90636, lr: 0.0000269, speed: 2.24 step/s\n",
      "global step 780, epoch: 1, batch: 780, loss: 0.18182, accu: 0.90586, lr: 0.0000272, speed: 2.33 step/s\n",
      "global step 790, epoch: 1, batch: 790, loss: 0.20622, accu: 0.90495, lr: 0.0000275, speed: 2.21 step/s\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.28241, accu: 0.90469, lr: 0.0000278, speed: 2.28 step/s\n",
      "eval dev loss: 0.33475, accu: 0.87628\n",
      "global step 810, epoch: 1, batch: 810, loss: 0.27243, accu: 0.92031, lr: 0.0000281, speed: 0.62 step/s\n",
      "global step 820, epoch: 1, batch: 820, loss: 0.21029, accu: 0.91406, lr: 0.0000284, speed: 2.26 step/s\n",
      "global step 830, epoch: 1, batch: 830, loss: 0.29111, accu: 0.90417, lr: 0.0000287, speed: 2.42 step/s\n",
      "global step 840, epoch: 1, batch: 840, loss: 0.24107, accu: 0.90020, lr: 0.0000290, speed: 2.07 step/s\n",
      "global step 850, epoch: 1, batch: 850, loss: 0.27533, accu: 0.90141, lr: 0.0000293, speed: 2.32 step/s\n",
      "global step 860, epoch: 1, batch: 860, loss: 0.26620, accu: 0.89935, lr: 0.0000296, speed: 2.26 step/s\n",
      "global step 870, epoch: 1, batch: 870, loss: 0.23240, accu: 0.90145, lr: 0.0000299, speed: 2.27 step/s\n",
      "global step 880, epoch: 1, batch: 880, loss: 0.29873, accu: 0.89980, lr: 0.0000302, speed: 2.24 step/s\n",
      "global step 890, epoch: 1, batch: 890, loss: 0.25429, accu: 0.89861, lr: 0.0000305, speed: 2.24 step/s\n",
      "global step 900, epoch: 1, batch: 900, loss: 0.16439, accu: 0.90172, lr: 0.0000308, speed: 2.24 step/s\n",
      "eval dev loss: 0.34336, accu: 0.88446\n",
      "global step 910, epoch: 1, batch: 910, loss: 0.24522, accu: 0.90234, lr: 0.0000311, speed: 0.63 step/s\n",
      "global step 920, epoch: 1, batch: 920, loss: 0.26495, accu: 0.90547, lr: 0.0000314, speed: 2.34 step/s\n",
      "global step 930, epoch: 1, batch: 930, loss: 0.17408, accu: 0.90495, lr: 0.0000317, speed: 2.19 step/s\n",
      "global step 940, epoch: 1, batch: 940, loss: 0.27051, accu: 0.90293, lr: 0.0000320, speed: 2.33 step/s\n",
      "global step 950, epoch: 1, batch: 950, loss: 0.19046, accu: 0.90516, lr: 0.0000323, speed: 2.30 step/s\n",
      "global step 960, epoch: 1, batch: 960, loss: 0.30930, accu: 0.90768, lr: 0.0000326, speed: 2.23 step/s\n",
      "global step 970, epoch: 1, batch: 970, loss: 0.19470, accu: 0.90658, lr: 0.0000329, speed: 2.54 step/s\n",
      "global step 980, epoch: 1, batch: 980, loss: 0.16679, accu: 0.90674, lr: 0.0000332, speed: 2.41 step/s\n",
      "global step 990, epoch: 1, batch: 990, loss: 0.24767, accu: 0.90616, lr: 0.0000335, speed: 2.21 step/s\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.21474, accu: 0.90719, lr: 0.0000338, speed: 2.33 step/s\n",
      "eval dev loss: 0.30415, accu: 0.88298\n",
      "global step 1010, epoch: 1, batch: 1010, loss: 0.19432, accu: 0.90859, lr: 0.0000341, speed: 0.68 step/s\n",
      "global step 1020, epoch: 1, batch: 1020, loss: 0.17263, accu: 0.90430, lr: 0.0000344, speed: 2.32 step/s\n",
      "global step 1030, epoch: 1, batch: 1030, loss: 0.20922, accu: 0.90443, lr: 0.0000347, speed: 2.27 step/s\n",
      "global step 1040, epoch: 1, batch: 1040, loss: 0.21579, accu: 0.90117, lr: 0.0000350, speed: 2.13 step/s\n",
      "global step 1050, epoch: 1, batch: 1050, loss: 0.24379, accu: 0.89750, lr: 0.0000353, speed: 2.35 step/s\n",
      "global step 1060, epoch: 1, batch: 1060, loss: 0.25639, accu: 0.89740, lr: 0.0000356, speed: 2.39 step/s\n",
      "global step 1070, epoch: 1, batch: 1070, loss: 0.14337, accu: 0.89855, lr: 0.0000359, speed: 2.54 step/s\n",
      "global step 1080, epoch: 1, batch: 1080, loss: 0.13678, accu: 0.89941, lr: 0.0000362, speed: 2.26 step/s\n",
      "global step 1090, epoch: 1, batch: 1090, loss: 0.17074, accu: 0.90095, lr: 0.0000365, speed: 2.23 step/s\n",
      "global step 1100, epoch: 1, batch: 1100, loss: 0.16183, accu: 0.90031, lr: 0.0000367, speed: 2.25 step/s\n",
      "eval dev loss: 0.25506, accu: 0.89775\n",
      "global step 1110, epoch: 1, batch: 1110, loss: 0.22908, accu: 0.92891, lr: 0.0000370, speed: 0.63 step/s\n",
      "global step 1120, epoch: 1, batch: 1120, loss: 0.21556, accu: 0.92461, lr: 0.0000373, speed: 2.44 step/s\n",
      "global step 1130, epoch: 1, batch: 1130, loss: 0.20726, accu: 0.91927, lr: 0.0000376, speed: 2.35 step/s\n",
      "global step 1140, epoch: 1, batch: 1140, loss: 0.16889, accu: 0.91563, lr: 0.0000379, speed: 2.25 step/s\n",
      "global step 1150, epoch: 1, batch: 1150, loss: 0.18894, accu: 0.91594, lr: 0.0000382, speed: 2.22 step/s\n",
      "global step 1160, epoch: 1, batch: 1160, loss: 0.25064, accu: 0.91471, lr: 0.0000385, speed: 2.61 step/s\n",
      "global step 1170, epoch: 1, batch: 1170, loss: 0.18103, accu: 0.91429, lr: 0.0000388, speed: 2.33 step/s\n",
      "global step 1180, epoch: 1, batch: 1180, loss: 0.22221, accu: 0.91406, lr: 0.0000391, speed: 2.43 step/s\n",
      "global step 1190, epoch: 1, batch: 1190, loss: 0.22956, accu: 0.91484, lr: 0.0000394, speed: 2.36 step/s\n",
      "global step 1200, epoch: 1, batch: 1200, loss: 0.18943, accu: 0.91328, lr: 0.0000397, speed: 2.40 step/s\n",
      "eval dev loss: 0.31803, accu: 0.86969\n",
      "global step 1210, epoch: 1, batch: 1210, loss: 0.22794, accu: 0.90312, lr: 0.0000400, speed: 0.67 step/s\n",
      "global step 1220, epoch: 1, batch: 1220, loss: 0.19728, accu: 0.90625, lr: 0.0000403, speed: 2.24 step/s\n",
      "global step 1230, epoch: 1, batch: 1230, loss: 0.16996, accu: 0.90286, lr: 0.0000406, speed: 2.43 step/s\n",
      "global step 1240, epoch: 1, batch: 1240, loss: 0.24631, accu: 0.90371, lr: 0.0000409, speed: 2.26 step/s\n",
      "global step 1250, epoch: 1, batch: 1250, loss: 0.17342, accu: 0.90859, lr: 0.0000412, speed: 2.28 step/s\n",
      "global step 1260, epoch: 1, batch: 1260, loss: 0.29319, accu: 0.90820, lr: 0.0000415, speed: 2.30 step/s\n",
      "global step 1270, epoch: 1, batch: 1270, loss: 0.19496, accu: 0.90938, lr: 0.0000418, speed: 2.28 step/s\n",
      "global step 1280, epoch: 1, batch: 1280, loss: 0.21970, accu: 0.90889, lr: 0.0000421, speed: 2.29 step/s\n",
      "global step 1290, epoch: 1, batch: 1290, loss: 0.19279, accu: 0.90911, lr: 0.0000424, speed: 2.36 step/s\n",
      "global step 1300, epoch: 1, batch: 1300, loss: 0.15352, accu: 0.90836, lr: 0.0000427, speed: 2.53 step/s\n",
      "eval dev loss: 0.31301, accu: 0.86401\n",
      "global step 1310, epoch: 1, batch: 1310, loss: 0.23343, accu: 0.91563, lr: 0.0000430, speed: 0.67 step/s\n",
      "global step 1320, epoch: 1, batch: 1320, loss: 0.14037, accu: 0.91406, lr: 0.0000433, speed: 2.45 step/s\n",
      "global step 1330, epoch: 1, batch: 1330, loss: 0.22864, accu: 0.91172, lr: 0.0000436, speed: 2.13 step/s\n",
      "global step 1340, epoch: 1, batch: 1340, loss: 0.22257, accu: 0.90840, lr: 0.0000439, speed: 2.22 step/s\n",
      "global step 1350, epoch: 1, batch: 1350, loss: 0.19255, accu: 0.90891, lr: 0.0000442, speed: 2.30 step/s\n",
      "global step 1360, epoch: 1, batch: 1360, loss: 0.29956, accu: 0.90833, lr: 0.0000445, speed: 2.25 step/s\n",
      "global step 1370, epoch: 1, batch: 1370, loss: 0.21845, accu: 0.90759, lr: 0.0000448, speed: 2.22 step/s\n",
      "global step 1380, epoch: 1, batch: 1380, loss: 0.20720, accu: 0.90889, lr: 0.0000451, speed: 2.44 step/s\n",
      "global step 1390, epoch: 1, batch: 1390, loss: 0.19946, accu: 0.90981, lr: 0.0000454, speed: 2.26 step/s\n",
      "global step 1400, epoch: 1, batch: 1400, loss: 0.22253, accu: 0.90836, lr: 0.0000457, speed: 2.40 step/s\n",
      "eval dev loss: 0.29086, accu: 0.8815\n",
      "global step 1410, epoch: 1, batch: 1410, loss: 0.14277, accu: 0.91094, lr: 0.0000460, speed: 0.66 step/s\n",
      "global step 1420, epoch: 1, batch: 1420, loss: 0.16921, accu: 0.91758, lr: 0.0000463, speed: 2.37 step/s\n",
      "global step 1430, epoch: 1, batch: 1430, loss: 0.23798, accu: 0.91302, lr: 0.0000466, speed: 2.40 step/s\n",
      "global step 1440, epoch: 1, batch: 1440, loss: 0.27026, accu: 0.90996, lr: 0.0000469, speed: 2.43 step/s\n",
      "global step 1450, epoch: 1, batch: 1450, loss: 0.23938, accu: 0.90734, lr: 0.0000472, speed: 2.33 step/s\n",
      "global step 1460, epoch: 1, batch: 1460, loss: 0.27664, accu: 0.90885, lr: 0.0000475, speed: 2.32 step/s\n",
      "global step 1470, epoch: 1, batch: 1470, loss: 0.26516, accu: 0.90871, lr: 0.0000478, speed: 2.26 step/s\n",
      "global step 1480, epoch: 1, batch: 1480, loss: 0.21162, accu: 0.90879, lr: 0.0000481, speed: 2.30 step/s\n",
      "global step 1490, epoch: 1, batch: 1490, loss: 0.24020, accu: 0.90781, lr: 0.0000484, speed: 2.33 step/s\n",
      "global step 1500, epoch: 1, batch: 1500, loss: 0.20551, accu: 0.90844, lr: 0.0000487, speed: 2.34 step/s\n",
      "eval dev loss: 0.2934, accu: 0.8915\n",
      "global step 1510, epoch: 1, batch: 1510, loss: 0.30906, accu: 0.89844, lr: 0.0000490, speed: 0.68 step/s\n",
      "global step 1520, epoch: 1, batch: 1520, loss: 0.27112, accu: 0.90391, lr: 0.0000493, speed: 2.33 step/s\n",
      "global step 1530, epoch: 1, batch: 1530, loss: 0.21091, accu: 0.90391, lr: 0.0000496, speed: 2.34 step/s\n",
      "global step 1540, epoch: 1, batch: 1540, loss: 0.23476, accu: 0.90742, lr: 0.0000499, speed: 2.26 step/s\n",
      "global step 1550, epoch: 1, batch: 1550, loss: 0.25335, accu: 0.90719, lr: 0.0000500, speed: 2.14 step/s\n",
      "global step 1560, epoch: 1, batch: 1560, loss: 0.16202, accu: 0.90586, lr: 0.0000499, speed: 2.63 step/s\n",
      "global step 1570, epoch: 1, batch: 1570, loss: 0.18524, accu: 0.90848, lr: 0.0000499, speed: 2.32 step/s\n",
      "global step 1580, epoch: 1, batch: 1580, loss: 0.27801, accu: 0.90820, lr: 0.0000498, speed: 2.33 step/s\n",
      "global step 1590, epoch: 1, batch: 1590, loss: 0.29138, accu: 0.90556, lr: 0.0000498, speed: 2.38 step/s\n",
      "global step 1600, epoch: 1, batch: 1600, loss: 0.20881, accu: 0.90516, lr: 0.0000497, speed: 2.28 step/s\n",
      "eval dev loss: 0.29637, accu: 0.88082\n",
      "global step 1610, epoch: 1, batch: 1610, loss: 0.29415, accu: 0.90859, lr: 0.0000497, speed: 0.68 step/s\n",
      "global step 1620, epoch: 1, batch: 1620, loss: 0.14165, accu: 0.90977, lr: 0.0000496, speed: 2.45 step/s\n",
      "global step 1630, epoch: 1, batch: 1630, loss: 0.33170, accu: 0.91224, lr: 0.0000496, speed: 2.39 step/s\n",
      "global step 1640, epoch: 1, batch: 1640, loss: 0.14849, accu: 0.91016, lr: 0.0000495, speed: 2.24 step/s\n",
      "global step 1650, epoch: 1, batch: 1650, loss: 0.15032, accu: 0.91187, lr: 0.0000494, speed: 2.27 step/s\n",
      "global step 1660, epoch: 1, batch: 1660, loss: 0.30897, accu: 0.91042, lr: 0.0000494, speed: 2.21 step/s\n",
      "global step 1670, epoch: 1, batch: 1670, loss: 0.24329, accu: 0.91016, lr: 0.0000493, speed: 2.34 step/s\n",
      "global step 1680, epoch: 1, batch: 1680, loss: 0.33730, accu: 0.90889, lr: 0.0000493, speed: 2.40 step/s\n",
      "global step 1690, epoch: 1, batch: 1690, loss: 0.31963, accu: 0.90755, lr: 0.0000492, speed: 2.28 step/s\n",
      "global step 1700, epoch: 1, batch: 1700, loss: 0.24993, accu: 0.90641, lr: 0.0000492, speed: 2.41 step/s\n",
      "eval dev loss: 0.27659, accu: 0.88696\n",
      "global step 1710, epoch: 1, batch: 1710, loss: 0.12882, accu: 0.91563, lr: 0.0000491, speed: 0.69 step/s\n",
      "global step 1720, epoch: 1, batch: 1720, loss: 0.12646, accu: 0.91680, lr: 0.0000491, speed: 2.24 step/s\n",
      "global step 1730, epoch: 1, batch: 1730, loss: 0.22452, accu: 0.91510, lr: 0.0000490, speed: 2.18 step/s\n",
      "global step 1740, epoch: 1, batch: 1740, loss: 0.19796, accu: 0.91680, lr: 0.0000490, speed: 2.16 step/s\n",
      "global step 1750, epoch: 1, batch: 1750, loss: 0.27972, accu: 0.91500, lr: 0.0000489, speed: 2.35 step/s\n",
      "global step 1760, epoch: 1, batch: 1760, loss: 0.17041, accu: 0.91432, lr: 0.0000489, speed: 2.32 step/s\n",
      "global step 1770, epoch: 1, batch: 1770, loss: 0.27587, accu: 0.91362, lr: 0.0000488, speed: 2.26 step/s\n",
      "global step 1780, epoch: 1, batch: 1780, loss: 0.31622, accu: 0.91172, lr: 0.0000488, speed: 2.30 step/s\n",
      "global step 1790, epoch: 1, batch: 1790, loss: 0.25580, accu: 0.90920, lr: 0.0000487, speed: 2.25 step/s\n",
      "global step 1800, epoch: 1, batch: 1800, loss: 0.23778, accu: 0.90984, lr: 0.0000487, speed: 2.35 step/s\n",
      "eval dev loss: 0.29379, accu: 0.88843\n",
      "global step 1810, epoch: 1, batch: 1810, loss: 0.26589, accu: 0.91719, lr: 0.0000486, speed: 0.68 step/s\n",
      "global step 1820, epoch: 1, batch: 1820, loss: 0.20754, accu: 0.90625, lr: 0.0000486, speed: 2.29 step/s\n",
      "global step 1830, epoch: 1, batch: 1830, loss: 0.22450, accu: 0.91094, lr: 0.0000485, speed: 2.26 step/s\n",
      "global step 1840, epoch: 1, batch: 1840, loss: 0.17589, accu: 0.91211, lr: 0.0000485, speed: 2.27 step/s\n",
      "global step 1850, epoch: 1, batch: 1850, loss: 0.25953, accu: 0.90859, lr: 0.0000484, speed: 2.24 step/s\n",
      "global step 1860, epoch: 1, batch: 1860, loss: 0.18985, accu: 0.90911, lr: 0.0000483, speed: 2.29 step/s\n",
      "global step 1870, epoch: 2, batch: 4, loss: 0.14499, accu: 0.91124, lr: 0.0000483, speed: 2.32 step/s\n",
      "global step 1880, epoch: 2, batch: 14, loss: 0.15871, accu: 0.91268, lr: 0.0000482, speed: 2.25 step/s\n",
      "global step 1890, epoch: 2, batch: 24, loss: 0.15810, accu: 0.91406, lr: 0.0000482, speed: 2.27 step/s\n",
      "global step 1900, epoch: 2, batch: 34, loss: 0.18097, accu: 0.91414, lr: 0.0000481, speed: 2.14 step/s\n",
      "eval dev loss: 0.32539, accu: 0.86128\n",
      "global step 1910, epoch: 2, batch: 44, loss: 0.12096, accu: 0.93359, lr: 0.0000481, speed: 0.69 step/s\n",
      "global step 1920, epoch: 2, batch: 54, loss: 0.29355, accu: 0.92031, lr: 0.0000480, speed: 2.16 step/s\n",
      "global step 1930, epoch: 2, batch: 64, loss: 0.17066, accu: 0.92344, lr: 0.0000480, speed: 2.31 step/s\n",
      "global step 1940, epoch: 2, batch: 74, loss: 0.12789, accu: 0.92129, lr: 0.0000479, speed: 2.37 step/s\n",
      "global step 1950, epoch: 2, batch: 84, loss: 0.11027, accu: 0.92297, lr: 0.0000479, speed: 2.30 step/s\n",
      "global step 1960, epoch: 2, batch: 94, loss: 0.26960, accu: 0.92174, lr: 0.0000478, speed: 2.37 step/s\n",
      "global step 1970, epoch: 2, batch: 104, loss: 0.24328, accu: 0.92042, lr: 0.0000478, speed: 2.42 step/s\n",
      "global step 1980, epoch: 2, batch: 114, loss: 0.14389, accu: 0.91992, lr: 0.0000477, speed: 2.30 step/s\n",
      "global step 1990, epoch: 2, batch: 124, loss: 0.22320, accu: 0.91953, lr: 0.0000477, speed: 2.24 step/s\n",
      "global step 2000, epoch: 2, batch: 134, loss: 0.20994, accu: 0.92055, lr: 0.0000476, speed: 2.44 step/s\n",
      "eval dev loss: 0.3286, accu: 0.87605\n",
      "global step 2010, epoch: 2, batch: 144, loss: 0.22457, accu: 0.91484, lr: 0.0000476, speed: 0.70 step/s\n",
      "global step 2020, epoch: 2, batch: 154, loss: 0.19312, accu: 0.91563, lr: 0.0000475, speed: 2.23 step/s\n",
      "global step 2030, epoch: 2, batch: 164, loss: 0.22508, accu: 0.92240, lr: 0.0000475, speed: 2.23 step/s\n",
      "global step 2040, epoch: 2, batch: 174, loss: 0.18204, accu: 0.92656, lr: 0.0000474, speed: 2.28 step/s\n",
      "global step 2050, epoch: 2, batch: 184, loss: 0.18886, accu: 0.92563, lr: 0.0000473, speed: 2.37 step/s\n",
      "global step 2060, epoch: 2, batch: 194, loss: 0.21749, accu: 0.92409, lr: 0.0000473, speed: 2.26 step/s\n",
      "global step 2070, epoch: 2, batch: 204, loss: 0.19353, accu: 0.92154, lr: 0.0000472, speed: 2.32 step/s\n",
      "global step 2080, epoch: 2, batch: 214, loss: 0.18259, accu: 0.92148, lr: 0.0000472, speed: 2.34 step/s\n",
      "global step 2090, epoch: 2, batch: 224, loss: 0.17684, accu: 0.92196, lr: 0.0000471, speed: 2.24 step/s\n",
      "global step 2100, epoch: 2, batch: 234, loss: 0.25030, accu: 0.92000, lr: 0.0000471, speed: 2.40 step/s\n",
      "eval dev loss: 0.29892, accu: 0.88355\n",
      "global step 2110, epoch: 2, batch: 244, loss: 0.20622, accu: 0.92422, lr: 0.0000470, speed: 0.69 step/s\n",
      "global step 2120, epoch: 2, batch: 254, loss: 0.17366, accu: 0.92773, lr: 0.0000470, speed: 2.25 step/s\n",
      "global step 2130, epoch: 2, batch: 264, loss: 0.21476, accu: 0.92630, lr: 0.0000469, speed: 2.26 step/s\n",
      "global step 2140, epoch: 2, batch: 274, loss: 0.16885, accu: 0.92344, lr: 0.0000469, speed: 2.35 step/s\n",
      "global step 2150, epoch: 2, batch: 284, loss: 0.08465, accu: 0.92547, lr: 0.0000468, speed: 2.29 step/s\n",
      "global step 2160, epoch: 2, batch: 294, loss: 0.20460, accu: 0.92331, lr: 0.0000468, speed: 2.19 step/s\n",
      "global step 2170, epoch: 2, batch: 304, loss: 0.24948, accu: 0.92277, lr: 0.0000467, speed: 2.31 step/s\n",
      "global step 2180, epoch: 2, batch: 314, loss: 0.16545, accu: 0.92168, lr: 0.0000467, speed: 2.46 step/s\n",
      "global step 2190, epoch: 2, batch: 324, loss: 0.18124, accu: 0.92214, lr: 0.0000466, speed: 2.25 step/s\n",
      "global step 2200, epoch: 2, batch: 334, loss: 0.11952, accu: 0.92266, lr: 0.0000466, speed: 2.32 step/s\n",
      "eval dev loss: 0.33186, accu: 0.87207\n",
      "global step 2210, epoch: 2, batch: 344, loss: 0.18512, accu: 0.92109, lr: 0.0000465, speed: 0.68 step/s\n",
      "global step 2220, epoch: 2, batch: 354, loss: 0.18851, accu: 0.92422, lr: 0.0000465, speed: 2.34 step/s\n",
      "global step 2230, epoch: 2, batch: 364, loss: 0.21346, accu: 0.92474, lr: 0.0000464, speed: 2.29 step/s\n",
      "global step 2240, epoch: 2, batch: 374, loss: 0.21288, accu: 0.92773, lr: 0.0000463, speed: 2.25 step/s\n",
      "global step 2250, epoch: 2, batch: 384, loss: 0.14784, accu: 0.93063, lr: 0.0000463, speed: 2.19 step/s\n",
      "global step 2260, epoch: 2, batch: 394, loss: 0.27049, accu: 0.92956, lr: 0.0000462, speed: 2.25 step/s\n",
      "global step 2270, epoch: 2, batch: 404, loss: 0.14413, accu: 0.92768, lr: 0.0000462, speed: 2.40 step/s\n",
      "global step 2280, epoch: 2, batch: 414, loss: 0.15234, accu: 0.92744, lr: 0.0000461, speed: 2.29 step/s\n",
      "global step 2290, epoch: 2, batch: 424, loss: 0.29632, accu: 0.92812, lr: 0.0000461, speed: 2.40 step/s\n",
      "global step 2300, epoch: 2, batch: 434, loss: 0.24224, accu: 0.92734, lr: 0.0000460, speed: 2.25 step/s\n",
      "eval dev loss: 0.28694, accu: 0.88491\n",
      "global step 2310, epoch: 2, batch: 444, loss: 0.19559, accu: 0.92188, lr: 0.0000460, speed: 0.68 step/s\n",
      "global step 2320, epoch: 2, batch: 454, loss: 0.23147, accu: 0.91992, lr: 0.0000459, speed: 2.18 step/s\n",
      "global step 2330, epoch: 2, batch: 464, loss: 0.30917, accu: 0.92083, lr: 0.0000459, speed: 2.45 step/s\n",
      "global step 2340, epoch: 2, batch: 474, loss: 0.20818, accu: 0.92305, lr: 0.0000458, speed: 2.23 step/s\n",
      "global step 2350, epoch: 2, batch: 484, loss: 0.16553, accu: 0.92297, lr: 0.0000458, speed: 2.18 step/s\n",
      "global step 2360, epoch: 2, batch: 494, loss: 0.21409, accu: 0.92344, lr: 0.0000457, speed: 2.45 step/s\n",
      "global step 2370, epoch: 2, batch: 504, loss: 0.22355, accu: 0.92288, lr: 0.0000457, speed: 2.40 step/s\n",
      "global step 2380, epoch: 2, batch: 514, loss: 0.17104, accu: 0.92441, lr: 0.0000456, speed: 2.38 step/s\n",
      "global step 2390, epoch: 2, batch: 524, loss: 0.12171, accu: 0.92405, lr: 0.0000456, speed: 2.33 step/s\n",
      "global step 2400, epoch: 2, batch: 534, loss: 0.23607, accu: 0.92508, lr: 0.0000455, speed: 2.29 step/s\n",
      "eval dev loss: 0.25405, accu: 0.90241\n",
      "global step 2410, epoch: 2, batch: 544, loss: 0.16045, accu: 0.91328, lr: 0.0000455, speed: 0.62 step/s\n",
      "global step 2420, epoch: 2, batch: 554, loss: 0.16865, accu: 0.91914, lr: 0.0000454, speed: 2.26 step/s\n",
      "global step 2430, epoch: 2, batch: 564, loss: 0.24339, accu: 0.92161, lr: 0.0000454, speed: 2.41 step/s\n",
      "global step 2440, epoch: 2, batch: 574, loss: 0.18021, accu: 0.92090, lr: 0.0000453, speed: 2.25 step/s\n",
      "global step 2450, epoch: 2, batch: 584, loss: 0.19505, accu: 0.92172, lr: 0.0000452, speed: 2.39 step/s\n",
      "global step 2460, epoch: 2, batch: 594, loss: 0.26132, accu: 0.92174, lr: 0.0000452, speed: 2.26 step/s\n",
      "global step 2470, epoch: 2, batch: 604, loss: 0.21511, accu: 0.92266, lr: 0.0000451, speed: 2.22 step/s\n",
      "global step 2480, epoch: 2, batch: 614, loss: 0.19752, accu: 0.92266, lr: 0.0000451, speed: 2.30 step/s\n",
      "global step 2490, epoch: 2, batch: 624, loss: 0.13323, accu: 0.92031, lr: 0.0000450, speed: 2.17 step/s\n",
      "global step 2500, epoch: 2, batch: 634, loss: 0.21912, accu: 0.92102, lr: 0.0000450, speed: 2.30 step/s\n",
      "eval dev loss: 0.30961, accu: 0.88628\n",
      "global step 2510, epoch: 2, batch: 644, loss: 0.23263, accu: 0.92656, lr: 0.0000449, speed: 0.69 step/s\n",
      "global step 2520, epoch: 2, batch: 654, loss: 0.21954, accu: 0.91719, lr: 0.0000449, speed: 2.35 step/s\n",
      "global step 2530, epoch: 2, batch: 664, loss: 0.12865, accu: 0.91693, lr: 0.0000448, speed: 2.36 step/s\n",
      "global step 2540, epoch: 2, batch: 674, loss: 0.17859, accu: 0.91738, lr: 0.0000448, speed: 2.43 step/s\n",
      "global step 2550, epoch: 2, batch: 684, loss: 0.05899, accu: 0.92219, lr: 0.0000447, speed: 2.31 step/s\n",
      "global step 2560, epoch: 2, batch: 694, loss: 0.19625, accu: 0.92474, lr: 0.0000447, speed: 2.42 step/s\n",
      "global step 2570, epoch: 2, batch: 704, loss: 0.17735, accu: 0.92400, lr: 0.0000446, speed: 2.37 step/s\n",
      "global step 2580, epoch: 2, batch: 714, loss: 0.19780, accu: 0.92500, lr: 0.0000446, speed: 2.31 step/s\n",
      "global step 2590, epoch: 2, batch: 724, loss: 0.13217, accu: 0.92526, lr: 0.0000445, speed: 2.26 step/s\n",
      "global step 2600, epoch: 2, batch: 734, loss: 0.12237, accu: 0.92555, lr: 0.0000445, speed: 2.28 step/s\n",
      "eval dev loss: 0.32819, accu: 0.88139\n",
      "global step 2610, epoch: 2, batch: 744, loss: 0.27724, accu: 0.92500, lr: 0.0000444, speed: 0.69 step/s\n",
      "global step 2620, epoch: 2, batch: 754, loss: 0.21813, accu: 0.91875, lr: 0.0000444, speed: 2.38 step/s\n",
      "global step 2630, epoch: 2, batch: 764, loss: 0.13550, accu: 0.92057, lr: 0.0000443, speed: 2.28 step/s\n",
      "global step 2640, epoch: 2, batch: 774, loss: 0.15804, accu: 0.92070, lr: 0.0000442, speed: 2.29 step/s\n",
      "global step 2650, epoch: 2, batch: 784, loss: 0.14751, accu: 0.92156, lr: 0.0000442, speed: 2.22 step/s\n",
      "global step 2660, epoch: 2, batch: 794, loss: 0.17694, accu: 0.92227, lr: 0.0000441, speed: 2.34 step/s\n",
      "global step 2670, epoch: 2, batch: 804, loss: 0.19436, accu: 0.92321, lr: 0.0000441, speed: 2.25 step/s\n",
      "global step 2680, epoch: 2, batch: 814, loss: 0.13011, accu: 0.92402, lr: 0.0000440, speed: 2.35 step/s\n",
      "global step 2690, epoch: 2, batch: 824, loss: 0.28993, accu: 0.92274, lr: 0.0000440, speed: 2.31 step/s\n",
      "global step 2700, epoch: 2, batch: 834, loss: 0.14044, accu: 0.92281, lr: 0.0000439, speed: 2.42 step/s\n",
      "eval dev loss: 0.28337, accu: 0.88707\n",
      "global step 2710, epoch: 2, batch: 844, loss: 0.20576, accu: 0.91172, lr: 0.0000439, speed: 0.69 step/s\n",
      "global step 2720, epoch: 2, batch: 854, loss: 0.25381, accu: 0.91758, lr: 0.0000438, speed: 2.47 step/s\n",
      "global step 2730, epoch: 2, batch: 864, loss: 0.24244, accu: 0.91797, lr: 0.0000438, speed: 2.22 step/s\n",
      "global step 2740, epoch: 2, batch: 874, loss: 0.11355, accu: 0.92207, lr: 0.0000437, speed: 2.31 step/s\n",
      "global step 2750, epoch: 2, batch: 884, loss: 0.13730, accu: 0.92016, lr: 0.0000437, speed: 2.39 step/s\n",
      "global step 2760, epoch: 2, batch: 894, loss: 0.18338, accu: 0.92135, lr: 0.0000436, speed: 2.45 step/s\n",
      "global step 2770, epoch: 2, batch: 904, loss: 0.20849, accu: 0.92154, lr: 0.0000436, speed: 2.22 step/s\n",
      "global step 2780, epoch: 2, batch: 914, loss: 0.19315, accu: 0.92070, lr: 0.0000435, speed: 2.37 step/s\n",
      "global step 2790, epoch: 2, batch: 924, loss: 0.24130, accu: 0.92083, lr: 0.0000435, speed: 2.30 step/s\n",
      "global step 2800, epoch: 2, batch: 934, loss: 0.21286, accu: 0.92023, lr: 0.0000434, speed: 2.22 step/s\n",
      "eval dev loss: 0.27972, accu: 0.88139\n",
      "global step 2810, epoch: 2, batch: 944, loss: 0.26514, accu: 0.92344, lr: 0.0000434, speed: 0.69 step/s\n",
      "global step 2820, epoch: 2, batch: 954, loss: 0.18369, accu: 0.92539, lr: 0.0000433, speed: 2.19 step/s\n",
      "global step 2830, epoch: 2, batch: 964, loss: 0.19503, accu: 0.92552, lr: 0.0000432, speed: 2.37 step/s\n",
      "global step 2840, epoch: 2, batch: 974, loss: 0.19727, accu: 0.92676, lr: 0.0000432, speed: 2.40 step/s\n",
      "global step 2850, epoch: 2, batch: 984, loss: 0.16349, accu: 0.92172, lr: 0.0000431, speed: 2.28 step/s\n",
      "global step 2860, epoch: 2, batch: 994, loss: 0.19714, accu: 0.91992, lr: 0.0000431, speed: 2.31 step/s\n",
      "global step 2870, epoch: 2, batch: 1004, loss: 0.09986, accu: 0.92154, lr: 0.0000430, speed: 2.31 step/s\n",
      "global step 2880, epoch: 2, batch: 1014, loss: 0.16217, accu: 0.92383, lr: 0.0000430, speed: 2.21 step/s\n",
      "global step 2890, epoch: 2, batch: 1024, loss: 0.13409, accu: 0.92439, lr: 0.0000429, speed: 2.21 step/s\n",
      "global step 2900, epoch: 2, batch: 1034, loss: 0.14487, accu: 0.92500, lr: 0.0000429, speed: 2.27 step/s\n",
      "eval dev loss: 0.26259, accu: 0.89616\n",
      "global step 2910, epoch: 2, batch: 1044, loss: 0.16924, accu: 0.92891, lr: 0.0000428, speed: 0.69 step/s\n",
      "global step 2920, epoch: 2, batch: 1054, loss: 0.19652, accu: 0.91875, lr: 0.0000428, speed: 2.35 step/s\n",
      "global step 2930, epoch: 2, batch: 1064, loss: 0.18431, accu: 0.92005, lr: 0.0000427, speed: 2.33 step/s\n",
      "global step 2940, epoch: 2, batch: 1074, loss: 0.14894, accu: 0.92148, lr: 0.0000427, speed: 2.27 step/s\n",
      "global step 2950, epoch: 2, batch: 1084, loss: 0.11989, accu: 0.92141, lr: 0.0000426, speed: 2.28 step/s\n",
      "global step 2960, epoch: 2, batch: 1094, loss: 0.17082, accu: 0.92188, lr: 0.0000426, speed: 2.21 step/s\n",
      "global step 2970, epoch: 2, batch: 1104, loss: 0.12244, accu: 0.92266, lr: 0.0000425, speed: 2.37 step/s\n",
      "global step 2980, epoch: 2, batch: 1114, loss: 0.18834, accu: 0.92236, lr: 0.0000425, speed: 2.24 step/s\n",
      "global step 2990, epoch: 2, batch: 1124, loss: 0.18821, accu: 0.92240, lr: 0.0000424, speed: 2.28 step/s\n",
      "global step 3000, epoch: 2, batch: 1134, loss: 0.11967, accu: 0.92266, lr: 0.0000424, speed: 2.36 step/s\n",
      "eval dev loss: 0.32118, accu: 0.88457\n",
      "global step 3010, epoch: 2, batch: 1144, loss: 0.09528, accu: 0.91563, lr: 0.0000423, speed: 0.69 step/s\n",
      "global step 3020, epoch: 2, batch: 1154, loss: 0.22422, accu: 0.92109, lr: 0.0000423, speed: 2.37 step/s\n",
      "global step 3030, epoch: 2, batch: 1164, loss: 0.16299, accu: 0.92214, lr: 0.0000422, speed: 2.23 step/s\n",
      "global step 3040, epoch: 2, batch: 1174, loss: 0.22107, accu: 0.92109, lr: 0.0000421, speed: 2.19 step/s\n",
      "global step 3050, epoch: 2, batch: 1184, loss: 0.18930, accu: 0.92266, lr: 0.0000421, speed: 2.30 step/s\n",
      "global step 3060, epoch: 2, batch: 1194, loss: 0.22647, accu: 0.92383, lr: 0.0000420, speed: 2.26 step/s\n",
      "global step 3070, epoch: 2, batch: 1204, loss: 0.23624, accu: 0.92467, lr: 0.0000420, speed: 2.39 step/s\n",
      "global step 3080, epoch: 2, batch: 1214, loss: 0.26100, accu: 0.92432, lr: 0.0000419, speed: 2.34 step/s\n",
      "global step 3090, epoch: 2, batch: 1224, loss: 0.18270, accu: 0.92422, lr: 0.0000419, speed: 2.19 step/s\n",
      "global step 3100, epoch: 2, batch: 1234, loss: 0.15494, accu: 0.92445, lr: 0.0000418, speed: 2.27 step/s\n",
      "eval dev loss: 0.26562, accu: 0.8998\n",
      "global step 3110, epoch: 2, batch: 1244, loss: 0.15333, accu: 0.92344, lr: 0.0000418, speed: 0.69 step/s\n",
      "global step 3120, epoch: 2, batch: 1254, loss: 0.24741, accu: 0.91797, lr: 0.0000417, speed: 2.45 step/s\n",
      "global step 3130, epoch: 2, batch: 1264, loss: 0.19423, accu: 0.91953, lr: 0.0000417, speed: 2.30 step/s\n",
      "global step 3140, epoch: 2, batch: 1274, loss: 0.13826, accu: 0.92266, lr: 0.0000416, speed: 2.39 step/s\n",
      "global step 3150, epoch: 2, batch: 1284, loss: 0.22192, accu: 0.92156, lr: 0.0000416, speed: 2.38 step/s\n",
      "global step 3160, epoch: 2, batch: 1294, loss: 0.13038, accu: 0.92240, lr: 0.0000415, speed: 2.42 step/s\n",
      "global step 3170, epoch: 2, batch: 1304, loss: 0.30037, accu: 0.92188, lr: 0.0000415, speed: 2.01 step/s\n",
      "global step 3180, epoch: 2, batch: 1314, loss: 0.25580, accu: 0.92207, lr: 0.0000414, speed: 2.26 step/s\n",
      "global step 3190, epoch: 2, batch: 1324, loss: 0.24538, accu: 0.92196, lr: 0.0000414, speed: 2.24 step/s\n",
      "global step 3200, epoch: 2, batch: 1334, loss: 0.18943, accu: 0.92242, lr: 0.0000413, speed: 2.51 step/s\n",
      "eval dev loss: 0.28849, accu: 0.8898\n",
      "global step 3210, epoch: 2, batch: 1344, loss: 0.16566, accu: 0.92422, lr: 0.0000413, speed: 0.67 step/s\n",
      "global step 3220, epoch: 2, batch: 1354, loss: 0.14298, accu: 0.92656, lr: 0.0000412, speed: 2.41 step/s\n",
      "global step 3230, epoch: 2, batch: 1364, loss: 0.19910, accu: 0.92786, lr: 0.0000411, speed: 2.39 step/s\n",
      "global step 3240, epoch: 2, batch: 1374, loss: 0.14775, accu: 0.92812, lr: 0.0000411, speed: 2.19 step/s\n",
      "global step 3250, epoch: 2, batch: 1384, loss: 0.26717, accu: 0.92906, lr: 0.0000410, speed: 2.18 step/s\n",
      "global step 3260, epoch: 2, batch: 1394, loss: 0.22133, accu: 0.92786, lr: 0.0000410, speed: 2.26 step/s\n",
      "global step 3270, epoch: 2, batch: 1404, loss: 0.18586, accu: 0.92824, lr: 0.0000409, speed: 2.25 step/s\n",
      "global step 3280, epoch: 2, batch: 1414, loss: 0.20580, accu: 0.92744, lr: 0.0000409, speed: 2.27 step/s\n",
      "global step 3290, epoch: 2, batch: 1424, loss: 0.13168, accu: 0.92760, lr: 0.0000408, speed: 2.37 step/s\n",
      "global step 3300, epoch: 2, batch: 1434, loss: 0.14248, accu: 0.92719, lr: 0.0000408, speed: 2.40 step/s\n",
      "eval dev loss: 0.28112, accu: 0.89377\n",
      "global step 3310, epoch: 2, batch: 1444, loss: 0.21534, accu: 0.91172, lr: 0.0000407, speed: 0.69 step/s\n",
      "global step 3320, epoch: 2, batch: 1454, loss: 0.15636, accu: 0.90977, lr: 0.0000407, speed: 2.35 step/s\n",
      "global step 3330, epoch: 2, batch: 1464, loss: 0.16724, accu: 0.91406, lr: 0.0000406, speed: 2.22 step/s\n",
      "global step 3340, epoch: 2, batch: 1474, loss: 0.19843, accu: 0.91836, lr: 0.0000406, speed: 2.35 step/s\n",
      "global step 3350, epoch: 2, batch: 1484, loss: 0.20942, accu: 0.91812, lr: 0.0000405, speed: 2.30 step/s\n",
      "global step 3360, epoch: 2, batch: 1494, loss: 0.14443, accu: 0.92096, lr: 0.0000405, speed: 2.31 step/s\n",
      "global step 3370, epoch: 2, batch: 1504, loss: 0.22480, accu: 0.92154, lr: 0.0000404, speed: 2.28 step/s\n",
      "global step 3380, epoch: 2, batch: 1514, loss: 0.15934, accu: 0.92246, lr: 0.0000404, speed: 2.37 step/s\n",
      "global step 3390, epoch: 2, batch: 1524, loss: 0.27819, accu: 0.92309, lr: 0.0000403, speed: 2.20 step/s\n",
      "global step 3400, epoch: 2, batch: 1534, loss: 0.20424, accu: 0.92297, lr: 0.0000403, speed: 2.18 step/s\n",
      "eval dev loss: 0.27737, accu: 0.88968\n",
      "global step 3410, epoch: 2, batch: 1544, loss: 0.21108, accu: 0.92188, lr: 0.0000402, speed: 0.68 step/s\n",
      "global step 3420, epoch: 2, batch: 1554, loss: 0.17171, accu: 0.92227, lr: 0.0000401, speed: 2.20 step/s\n",
      "global step 3430, epoch: 2, batch: 1564, loss: 0.18747, accu: 0.92057, lr: 0.0000401, speed: 2.18 step/s\n",
      "global step 3440, epoch: 2, batch: 1574, loss: 0.24915, accu: 0.92227, lr: 0.0000400, speed: 2.40 step/s\n",
      "global step 3450, epoch: 2, batch: 1584, loss: 0.20018, accu: 0.92281, lr: 0.0000400, speed: 2.13 step/s\n",
      "global step 3460, epoch: 2, batch: 1594, loss: 0.18034, accu: 0.92318, lr: 0.0000399, speed: 2.35 step/s\n",
      "global step 3470, epoch: 2, batch: 1604, loss: 0.26173, accu: 0.92556, lr: 0.0000399, speed: 2.20 step/s\n",
      "global step 3480, epoch: 2, batch: 1614, loss: 0.14198, accu: 0.92676, lr: 0.0000398, speed: 2.24 step/s\n",
      "global step 3490, epoch: 2, batch: 1624, loss: 0.20083, accu: 0.92760, lr: 0.0000398, speed: 2.36 step/s\n",
      "global step 3500, epoch: 2, batch: 1634, loss: 0.19702, accu: 0.92797, lr: 0.0000397, speed: 2.27 step/s\n",
      "eval dev loss: 0.297, accu: 0.8815\n",
      "global step 3510, epoch: 2, batch: 1644, loss: 0.16398, accu: 0.92266, lr: 0.0000397, speed: 0.70 step/s\n",
      "global step 3520, epoch: 2, batch: 1654, loss: 0.18623, accu: 0.92578, lr: 0.0000396, speed: 2.25 step/s\n",
      "global step 3530, epoch: 2, batch: 1664, loss: 0.17568, accu: 0.92109, lr: 0.0000396, speed: 2.33 step/s\n",
      "global step 3540, epoch: 2, batch: 1674, loss: 0.18494, accu: 0.91992, lr: 0.0000395, speed: 2.26 step/s\n",
      "global step 3550, epoch: 2, batch: 1684, loss: 0.19815, accu: 0.92109, lr: 0.0000395, speed: 2.28 step/s\n",
      "global step 3560, epoch: 2, batch: 1694, loss: 0.21080, accu: 0.92070, lr: 0.0000394, speed: 2.36 step/s\n",
      "global step 3570, epoch: 2, batch: 1704, loss: 0.14478, accu: 0.92132, lr: 0.0000394, speed: 2.29 step/s\n",
      "global step 3580, epoch: 2, batch: 1714, loss: 0.20818, accu: 0.92275, lr: 0.0000393, speed: 2.12 step/s\n",
      "global step 3590, epoch: 2, batch: 1724, loss: 0.19995, accu: 0.92266, lr: 0.0000393, speed: 2.16 step/s\n",
      "global step 3600, epoch: 2, batch: 1734, loss: 0.18898, accu: 0.92211, lr: 0.0000392, speed: 2.30 step/s\n",
      "eval dev loss: 0.28431, accu: 0.89173\n",
      "global step 3610, epoch: 2, batch: 1744, loss: 0.20299, accu: 0.92109, lr: 0.0000392, speed: 0.68 step/s\n",
      "global step 3620, epoch: 2, batch: 1754, loss: 0.15272, accu: 0.92227, lr: 0.0000391, speed: 2.26 step/s\n",
      "global step 3630, epoch: 2, batch: 1764, loss: 0.09644, accu: 0.92604, lr: 0.0000390, speed: 2.45 step/s\n",
      "global step 3640, epoch: 2, batch: 1774, loss: 0.21496, accu: 0.92441, lr: 0.0000390, speed: 2.26 step/s\n",
      "global step 3650, epoch: 2, batch: 1784, loss: 0.20949, accu: 0.92781, lr: 0.0000389, speed: 2.19 step/s\n",
      "global step 3660, epoch: 2, batch: 1794, loss: 0.15477, accu: 0.92708, lr: 0.0000389, speed: 2.43 step/s\n",
      "global step 3670, epoch: 2, batch: 1804, loss: 0.21094, accu: 0.92533, lr: 0.0000388, speed: 2.33 step/s\n",
      "global step 3680, epoch: 2, batch: 1814, loss: 0.25116, accu: 0.92324, lr: 0.0000388, speed: 2.26 step/s\n",
      "global step 3690, epoch: 2, batch: 1824, loss: 0.21079, accu: 0.92465, lr: 0.0000387, speed: 2.50 step/s\n",
      "global step 3700, epoch: 2, batch: 1834, loss: 0.16270, accu: 0.92422, lr: 0.0000387, speed: 2.25 step/s\n",
      "eval dev loss: 0.27027, accu: 0.89582\n",
      "global step 3710, epoch: 2, batch: 1844, loss: 0.14874, accu: 0.91875, lr: 0.0000386, speed: 0.68 step/s\n",
      "global step 3720, epoch: 2, batch: 1854, loss: 0.17796, accu: 0.92852, lr: 0.0000386, speed: 2.27 step/s\n",
      "global step 3730, epoch: 2, batch: 1864, loss: 0.27354, accu: 0.92604, lr: 0.0000385, speed: 2.48 step/s\n",
      "global step 3740, epoch: 3, batch: 8, loss: 0.11213, accu: 0.92954, lr: 0.0000385, speed: 2.44 step/s\n",
      "global step 3750, epoch: 3, batch: 18, loss: 0.26783, accu: 0.92877, lr: 0.0000384, speed: 2.26 step/s\n",
      "global step 3760, epoch: 3, batch: 28, loss: 0.19930, accu: 0.92919, lr: 0.0000384, speed: 2.40 step/s\n",
      "global step 3770, epoch: 3, batch: 38, loss: 0.07218, accu: 0.93174, lr: 0.0000383, speed: 2.34 step/s\n",
      "global step 3780, epoch: 3, batch: 48, loss: 0.15691, accu: 0.93237, lr: 0.0000383, speed: 2.40 step/s\n",
      "global step 3790, epoch: 3, batch: 58, loss: 0.15258, accu: 0.93338, lr: 0.0000382, speed: 2.27 step/s\n",
      "global step 3800, epoch: 3, batch: 68, loss: 0.10811, accu: 0.93332, lr: 0.0000382, speed: 2.52 step/s\n",
      "eval dev loss: 0.29281, accu: 0.89252\n",
      "global step 3810, epoch: 3, batch: 78, loss: 0.09405, accu: 0.94297, lr: 0.0000381, speed: 0.68 step/s\n",
      "global step 3820, epoch: 3, batch: 88, loss: 0.15192, accu: 0.93633, lr: 0.0000380, speed: 2.41 step/s\n",
      "global step 3830, epoch: 3, batch: 98, loss: 0.10513, accu: 0.93516, lr: 0.0000380, speed: 2.28 step/s\n",
      "global step 3840, epoch: 3, batch: 108, loss: 0.15860, accu: 0.93672, lr: 0.0000379, speed: 2.32 step/s\n",
      "global step 3850, epoch: 3, batch: 118, loss: 0.08400, accu: 0.93719, lr: 0.0000379, speed: 2.28 step/s\n",
      "global step 3860, epoch: 3, batch: 128, loss: 0.20864, accu: 0.93828, lr: 0.0000378, speed: 2.34 step/s\n",
      "global step 3870, epoch: 3, batch: 138, loss: 0.20808, accu: 0.93795, lr: 0.0000378, speed: 2.34 step/s\n",
      "global step 3880, epoch: 3, batch: 148, loss: 0.14664, accu: 0.93770, lr: 0.0000377, speed: 2.29 step/s\n",
      "global step 3890, epoch: 3, batch: 158, loss: 0.12229, accu: 0.93993, lr: 0.0000377, speed: 2.26 step/s\n",
      "global step 3900, epoch: 3, batch: 168, loss: 0.09860, accu: 0.94008, lr: 0.0000376, speed: 2.26 step/s\n",
      "eval dev loss: 0.30448, accu: 0.89093\n",
      "global step 3910, epoch: 3, batch: 178, loss: 0.21242, accu: 0.93906, lr: 0.0000376, speed: 0.68 step/s\n",
      "global step 3920, epoch: 3, batch: 188, loss: 0.13765, accu: 0.93594, lr: 0.0000375, speed: 2.39 step/s\n",
      "global step 3930, epoch: 3, batch: 198, loss: 0.09754, accu: 0.93620, lr: 0.0000375, speed: 2.13 step/s\n",
      "global step 3940, epoch: 3, batch: 208, loss: 0.09600, accu: 0.93789, lr: 0.0000374, speed: 2.19 step/s\n",
      "global step 3950, epoch: 3, batch: 218, loss: 0.11298, accu: 0.93875, lr: 0.0000374, speed: 2.26 step/s\n",
      "global step 3960, epoch: 3, batch: 228, loss: 0.20310, accu: 0.93789, lr: 0.0000373, speed: 2.28 step/s\n",
      "global step 3970, epoch: 3, batch: 238, loss: 0.12367, accu: 0.93906, lr: 0.0000373, speed: 2.43 step/s\n",
      "global step 3980, epoch: 3, batch: 248, loss: 0.20049, accu: 0.93828, lr: 0.0000372, speed: 2.39 step/s\n",
      "global step 3990, epoch: 3, batch: 258, loss: 0.13519, accu: 0.93889, lr: 0.0000372, speed: 2.26 step/s\n",
      "global step 4000, epoch: 3, batch: 268, loss: 0.11800, accu: 0.93836, lr: 0.0000371, speed: 2.21 step/s\n",
      "eval dev loss: 0.29235, accu: 0.89832\n",
      "global step 4010, epoch: 3, batch: 278, loss: 0.11792, accu: 0.93828, lr: 0.0000370, speed: 0.67 step/s\n",
      "global step 4020, epoch: 3, batch: 288, loss: 0.16269, accu: 0.93984, lr: 0.0000370, speed: 2.45 step/s\n",
      "global step 4030, epoch: 3, batch: 298, loss: 0.16272, accu: 0.93958, lr: 0.0000369, speed: 2.18 step/s\n",
      "global step 4040, epoch: 3, batch: 308, loss: 0.13591, accu: 0.93906, lr: 0.0000369, speed: 2.33 step/s\n",
      "global step 4050, epoch: 3, batch: 318, loss: 0.12879, accu: 0.93734, lr: 0.0000368, speed: 2.33 step/s\n",
      "global step 4060, epoch: 3, batch: 328, loss: 0.13270, accu: 0.93594, lr: 0.0000368, speed: 2.29 step/s\n",
      "global step 4070, epoch: 3, batch: 338, loss: 0.11520, accu: 0.93839, lr: 0.0000367, speed: 2.33 step/s\n",
      "global step 4080, epoch: 3, batch: 348, loss: 0.26667, accu: 0.93838, lr: 0.0000367, speed: 2.32 step/s\n",
      "global step 4090, epoch: 3, batch: 358, loss: 0.14807, accu: 0.93872, lr: 0.0000366, speed: 2.45 step/s\n",
      "global step 4100, epoch: 3, batch: 368, loss: 0.13414, accu: 0.93914, lr: 0.0000366, speed: 2.33 step/s\n",
      "eval dev loss: 0.31162, accu: 0.89025\n",
      "global step 4110, epoch: 3, batch: 378, loss: 0.13120, accu: 0.92500, lr: 0.0000365, speed: 0.68 step/s\n",
      "global step 4120, epoch: 3, batch: 388, loss: 0.17088, accu: 0.92266, lr: 0.0000365, speed: 2.28 step/s\n",
      "global step 4130, epoch: 3, batch: 398, loss: 0.12426, accu: 0.92865, lr: 0.0000364, speed: 2.28 step/s\n",
      "global step 4140, epoch: 3, batch: 408, loss: 0.03447, accu: 0.93086, lr: 0.0000364, speed: 2.41 step/s\n",
      "global step 4150, epoch: 3, batch: 418, loss: 0.11070, accu: 0.93125, lr: 0.0000363, speed: 2.32 step/s\n",
      "global step 4160, epoch: 3, batch: 428, loss: 0.15601, accu: 0.93333, lr: 0.0000363, speed: 2.27 step/s\n",
      "global step 4170, epoch: 3, batch: 438, loss: 0.11699, accu: 0.93382, lr: 0.0000362, speed: 2.16 step/s\n",
      "global step 4180, epoch: 3, batch: 448, loss: 0.12330, accu: 0.93486, lr: 0.0000362, speed: 2.19 step/s\n",
      "global step 4190, epoch: 3, batch: 458, loss: 0.12707, accu: 0.93498, lr: 0.0000361, speed: 2.32 step/s\n",
      "global step 4200, epoch: 3, batch: 468, loss: 0.14987, accu: 0.93469, lr: 0.0000361, speed: 2.33 step/s\n",
      "eval dev loss: 0.29751, accu: 0.87798\n",
      "global step 4210, epoch: 3, batch: 478, loss: 0.17292, accu: 0.93125, lr: 0.0000360, speed: 0.68 step/s\n",
      "global step 4220, epoch: 3, batch: 488, loss: 0.19252, accu: 0.93281, lr: 0.0000359, speed: 2.15 step/s\n",
      "global step 4230, epoch: 3, batch: 498, loss: 0.25215, accu: 0.93490, lr: 0.0000359, speed: 2.38 step/s\n",
      "global step 4240, epoch: 3, batch: 508, loss: 0.11344, accu: 0.93594, lr: 0.0000358, speed: 2.36 step/s\n",
      "global step 4250, epoch: 3, batch: 518, loss: 0.15531, accu: 0.93391, lr: 0.0000358, speed: 2.32 step/s\n",
      "global step 4260, epoch: 3, batch: 528, loss: 0.13165, accu: 0.93190, lr: 0.0000357, speed: 2.22 step/s\n",
      "global step 4270, epoch: 3, batch: 538, loss: 0.18445, accu: 0.93158, lr: 0.0000357, speed: 2.32 step/s\n",
      "global step 4280, epoch: 3, batch: 548, loss: 0.13416, accu: 0.93223, lr: 0.0000356, speed: 2.34 step/s\n",
      "global step 4290, epoch: 3, batch: 558, loss: 0.13220, accu: 0.93212, lr: 0.0000356, speed: 2.38 step/s\n",
      "global step 4300, epoch: 3, batch: 568, loss: 0.10220, accu: 0.93336, lr: 0.0000355, speed: 2.38 step/s\n",
      "eval dev loss: 0.31664, accu: 0.88219\n",
      "global step 4310, epoch: 3, batch: 578, loss: 0.14709, accu: 0.93906, lr: 0.0000355, speed: 0.67 step/s\n",
      "global step 4320, epoch: 3, batch: 588, loss: 0.17965, accu: 0.93633, lr: 0.0000354, speed: 2.25 step/s\n",
      "global step 4330, epoch: 3, batch: 598, loss: 0.09203, accu: 0.93516, lr: 0.0000354, speed: 2.37 step/s\n",
      "global step 4340, epoch: 3, batch: 608, loss: 0.14626, accu: 0.93730, lr: 0.0000353, speed: 2.31 step/s\n",
      "global step 4350, epoch: 3, batch: 618, loss: 0.26010, accu: 0.93797, lr: 0.0000353, speed: 2.28 step/s\n",
      "global step 4360, epoch: 3, batch: 628, loss: 0.16373, accu: 0.93841, lr: 0.0000352, speed: 2.29 step/s\n",
      "global step 4370, epoch: 3, batch: 638, loss: 0.20931, accu: 0.93705, lr: 0.0000352, speed: 2.38 step/s\n",
      "global step 4380, epoch: 3, batch: 648, loss: 0.06896, accu: 0.93740, lr: 0.0000351, speed: 2.12 step/s\n",
      "global step 4390, epoch: 3, batch: 658, loss: 0.09559, accu: 0.93863, lr: 0.0000351, speed: 2.37 step/s\n",
      "global step 4400, epoch: 3, batch: 668, loss: 0.09938, accu: 0.93937, lr: 0.0000350, speed: 2.34 step/s\n",
      "eval dev loss: 0.28439, accu: 0.89957\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "from visualdl import LogWriter\n",
    "writer = LogWriter(\"./log_lcqmc_2\")\n",
    "save_dir = \"checkpoint_lcqmc_2\"\n",
    "use_cuda = True # 如想使用GPU，请设置为 True\n",
    "https://paddlenlp.bj.bcebos.com/models/text_matching/ernie_gram_zh_pointwise_matching_model.tar(model, optimizer, epochs, criterion, metric, save_dir, tokenizer, loader_list=[train_data_loader, dev_data_loader], lr_scheduler=lr_scheduler, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "谁有狂三这张高清的\t这张高清图，谁有\r\n",
      "英雄联盟什么英雄最好\t英雄联盟最好英雄是什么\r\n",
      "这是什么意思，被蹭网吗\t我也是醉了，这是什么意思\r\n"
     ]
    }
   ],
   "source": [
    "! head -n3 \"${HOME}/.paddlenlp/datasets/LCQMC/lcqmc/lcqmc/test.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 定义预测函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 定义预测数据的 data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_ds length 12500\n"
     ]
    }
   ],
   "source": [
    "# 预测数据的转换函数\n",
    "# predict 数据没有 label, 因此 convert_exmaple 的 is_test 参数设为 True\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512,\n",
    "    is_test=True)\n",
    "\n",
    "# 加载预测数据\n",
    "test_ds = load_dataset(\"lcqmc\", splits=[\"test\"])\n",
    "print('test_ds length', len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict dataloader length: 98\n"
     ]
    }
   ],
   "source": [
    "# 生成预测数据 data_loader\n",
    "predict_data_loader = create_dataloader(dataset=test_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='test',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "print(\"predict dataloader length:\", len(predict_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 定义预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-17 09:33:12,475] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "model = PointwiseMatching(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 加载已训练好的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_dict = paddle.load(\"checkpoint_lcqmc_2/best_model_state.pdparams\")\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 开始预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[128, 38], dtype=int64, place=CUDAPinnedPlace, stop_gradient=True,\n",
      "       [[1   , 1022, 9   , ..., 0   , 0   , 0   ],\n",
      "        [1   , 514 , 904 , ..., 0   , 0   , 0   ],\n",
      "        [1   , 47  , 10  , ..., 0   , 0   , 0   ],\n",
      "        ...,\n",
      "        [1   , 936 , 356 , ..., 0   , 0   , 0   ],\n",
      "        [1   , 614 , 356 , ..., 0   , 0   , 0   ],\n",
      "        [1   , 630 , 1099, ..., 0   , 0   , 0   ]]), Tensor(shape=[128, 38], dtype=int64, place=CUDAPinnedPlace, stop_gradient=True,\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]])]\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(predict_data_loader):\n",
    "    if idx < 1:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_probs = predict(model, predict_data_loader)\n",
    "y_preds = np.argmax(y_probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 输出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '谁有狂三这张高清的', 'title': '这张高清图，谁有', 'label': 0}\n",
      "{'query': '英雄联盟什么英雄最好', 'title': '英雄联盟最好英雄是什么', 'label': 1}\n",
      "{'query': '这是什么意思，被蹭网吗', 'title': '我也是醉了，这是什么意思', 'label': 1}\n",
      "{'query': '现在有什么动画片好看呢？', 'title': '现在有什么好看的动画片吗？', 'label': 1}\n",
      "{'query': '请问晶达电子厂现在的工资待遇怎么样要求有哪些', 'title': '三星电子厂工资待遇怎么样啊', 'label': 0}\n",
      "{'query': '文章真的爱姚笛吗', 'title': '姚笛真的被文章干了吗', 'label': 0}\n",
      "{'query': '送自己做的闺蜜什么生日礼物好', 'title': '送闺蜜什么生日礼物好', 'label': 1}\n",
      "{'query': '近期上映的电影', 'title': '近期上映的电影有哪些', 'label': 1}\n",
      "{'query': '求英雄联盟大神带？', 'title': '英雄联盟，求大神带~', 'label': 1}\n",
      "{'query': '如加上什么部首', 'title': '给东加上部首是什么字？', 'label': 0}\n",
      "{'query': '杭州哪里好玩', 'title': '杭州哪里好玩点', 'label': 1}\n",
      "{'query': '这是什么乌龟值钱吗', 'title': '这是什么乌龟！值钱嘛？', 'label': 1}\n",
      "{'query': '心各有所属是什么意思？', 'title': '心有所属是什么意思?', 'label': 1}\n",
      "{'query': '什么东西越热爬得越高', 'title': '什么东西越热爬得很高', 'label': 1}\n",
      "{'query': '世界杯哪位球员进球最多', 'title': '世界杯单界进球最多是哪位球员', 'label': 1}\n",
      "{'query': '韭菜多吃什么好处', 'title': '多吃韭菜有什么好处', 'label': 1}\n",
      "{'query': '云赚钱怎么样', 'title': '怎么才能赚钱', 'label': 0}\n",
      "{'query': '何炅结婚了嘛', 'title': '何炅结婚了么', 'label': 1}\n",
      "{'query': '长的清新是什么意思', 'title': '小清新的意思是什么', 'label': 0}\n",
      "{'query': '我们可以结婚了吗？', 'title': '在熙结婚了吗？', 'label': 0}\n",
      "{'query': '想买男人酒补肾壮阳酒哪里有啊', 'title': '哪里有男人酒补肾壮阳酒', 'label': 1}\n",
      "{'query': '淘宝上怎么用信用卡分期付款', 'title': '淘宝怎么分期付款，没有信用卡', 'label': 0}\n",
      "{'query': '最近有没有什么好看的韩剧', 'title': '最近有什么好看的韩剧', 'label': 1}\n",
      "{'query': '《校花的贴身高手》中的林逸', 'title': '校花贴身高手', 'label': 1}\n",
      "{'query': '叔叔是什么人', 'title': '我是叔叔的什么人', 'label': 0}\n",
      "{'query': '这姑娘漂亮不', 'title': '我姑娘漂亮吧', 'label': 1}\n",
      "{'query': '在淘宝网买手机可靠吗？', 'title': '在淘宝网上买手机可靠吗？', 'label': 1}\n",
      "{'query': '山楂干怎么吃好吃？', 'title': '山楂怎么做好吃', 'label': 0}\n",
      "{'query': '时间都去哪怕了歌谱', 'title': '时间煮雨歌谱', 'label': 0}\n",
      "{'query': '苏州哪里能买到这个衣服', 'title': '苏州哪里有买大号衣服的？', 'label': 0}\n",
      "{'query': '最好玩的手机网游', 'title': '好玩的手机网游', 'label': 1}\n",
      "{'query': '石榴是什么时候成熟的？', 'title': '成熟的石榴像什么？', 'label': 0}\n",
      "{'query': '刘诗诗杨幂谁漂亮', 'title': '刘诗诗和杨幂谁漂亮', 'label': 1}\n",
      "{'query': '微信号怎么二次修改', 'title': '怎么再二次修改微信号', 'label': 1}\n",
      "{'query': '什么牌子的精油皂好', 'title': '什么牌子的精油好？', 'label': 0}\n",
      "{'query': '刚出生的小野鸡怎么养', 'title': '刚抓来的野鸡怎么养殖', 'label': 0}\n",
      "{'query': '如何入侵他人手机', 'title': '如何入侵别人的手机', 'label': 1}\n",
      "{'query': '红米刷什么系统好', 'title': '红米可以刷什么系统', 'label': 1}\n",
      "{'query': '这叫什么高跟鞋', 'title': '这种高跟鞋叫什么呀', 'label': 1}\n",
      "{'query': '汇理财怎么样', 'title': '怎么样去理财？', 'label': 0}\n",
      "{'query': '什么是刷屏', 'title': '什么叫刷屏？', 'label': 1}\n",
      "{'query': '各国货币符号是什么?', 'title': '如何用电脑打出各国货币符号呀', 'label': 0}\n",
      "{'query': '上嘴唇有痣代表什么', 'title': '咬嘴唇代表什么', 'label': 0}\n",
      "{'query': '哪种减肥药最快最有效', 'title': '哪种减肥药最有效，减肥效果最好', 'label': 1}\n",
      "{'query': '邓紫棋唱功怎么样', 'title': '邓紫棋唱功怎么样？', 'label': 1}\n",
      "{'query': '怎么做视频', 'title': '贴吧怎么贴视频', 'label': 0}\n",
      "{'query': '现在女生流行什么发型？', 'title': '女生现在流行什么发型？', 'label': 1}\n",
      "{'query': '为什么坐车玩手机会晕车', 'title': '为什么我坐车玩手机不晕车', 'label': 1}\n",
      "{'query': '为什么老婆不喜欢和我做爱', 'title': '我老婆为什么不喜欢做爱', 'label': 1}\n",
      "{'query': '怎么测试我爱的他爱不爱我。', 'title': '怎么测试老公爱不爱我啊', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "test_ds = load_dataset(\"lcqmc\", splits=[\"test\"])\n",
    "tsv_name = 'lcqmc.tsv'\n",
    "write_tsv(tsv_name, test_ds, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## bq_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.BAIDUData'>\n",
      "train dataset length: 100000\n",
      "dev dataset length: 10000\n",
      "{'query': '用微信都6年，微信没有微粒贷功能', 'title': '4。号码来微粒贷', 'label': 0}\n",
      "{'query': '微信消费算吗', 'title': '还有多少钱没还', 'label': 0}\n",
      "{'query': '交易密码忘记了找回密码绑定的手机卡也掉了', 'title': '怎么最近安全老是要改密码呢好麻烦', 'label': 0}\n",
      "{'query': '你好我昨天晚上申请的没有打电话给我今天之内一定会打吗？', 'title': '什么时候可以到账', 'label': 0}\n",
      "{'query': '“微粒贷开通\"', 'title': '你好，我的微粒贷怎么没有开通呢', 'label': 0}\n",
      "{'query': '为什么借款后一直没有给我回拨电话', 'title': '怎么申请借款后没有打电话过来呢！', 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-13 12:57:27,594] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-gram-zh/vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataloader length: 782\n",
      "dev dataloader length: 79\n"
     ]
    }
   ],
   "source": [
    "train_ds, dev_ds = load_my_dataset(splits=[\"train\", \"dev\"], SPLITS={'train':'data/bq_corpus/train.tsv', 'dev':'data/bq_corpus/dev.tsv'})\n",
    "print(\"train dataset length:\", len(train_ds))\n",
    "print(\"dev dataset length:\", len(dev_ds))\n",
    "\n",
    "# 输出训练集的前 5 条样本\n",
    "for idx, example in enumerate(train_ds):\n",
    "    if idx <= 5:\n",
    "        print(example)\n",
    "\n",
    "tokenizer = paddlenlp.transformers.ErnieGramTokenizer.from_pretrained('ernie-gram-zh')\n",
    "\n",
    "# 训练集和验证集的样本转换函数\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512,\n",
    "    is_flip=True)\n",
    "\n",
    "batch_size = 128\n",
    "train_data_loader = create_dataloader(dataset=train_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='train',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512)\n",
    "\n",
    "dev_data_loader = create_dataloader(dataset=dev_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='dev',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "print(\"train dataloader length:\", len(train_data_loader))\n",
    "print(\"dev dataloader length:\", len(dev_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-13 12:57:30,246] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "model = PointwiseMatching(pretrained_model, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "epochs = 10\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate=3e-5, total_steps=num_training_steps, warmup=0.1)\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=0.0,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.69938, accu: 0.50469, lr: 0.0000003, speed: 2.00 step/s\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.78842, accu: 0.49688, lr: 0.0000007, speed: 2.01 step/s\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.73961, accu: 0.50182, lr: 0.0000011, speed: 1.97 step/s\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.78163, accu: 0.49355, lr: 0.0000015, speed: 2.04 step/s\n"
     ]
    }
   ],
   "source": [
    "from visualdl import LogWriter\n",
    "writer = LogWriter(\"./log_bq_corpus_3\")\n",
    "save_dir = \"checkpoint_bq_corpus_3\"\n",
    "\n",
    "train_model(model, optimizer, epochs, criterion, metric, save_dir, tokenizer, loader_list=[train_data_loader, dev_data_loader], patience=patience, lr_scheduler=lr_scheduler, writer=writer, add_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-13 02:41:45,963] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "model = PointwiseMatching(pretrained_model, dropout=0.3)\n",
    "state_dict = paddle.load(\"checkpoint_bq_corpus_4/best_model_state.pdparams\")\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.BAIDUData'>\n",
      "test_ds length 10000\n",
      "predict dataloader length: 79\n"
     ]
    }
   ],
   "source": [
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512,\n",
    "    is_test=True)\n",
    "    \n",
    "test_ds = load_my_dataset(splits=[\"test\"], SPLITS={'test':'data/bq_corpus/test.tsv'})\n",
    "print('test_ds length', len(test_ds))\n",
    "\n",
    "predict_data_loader = create_dataloader(dataset=test_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='test',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "print(\"predict dataloader length:\", len(predict_data_loader))\n",
    "\n",
    "y_probs = predict(model, predict_data_loader)\n",
    "\n",
    "y_preds = np.argmax(y_probs, axis=1)\n",
    "\n",
    "test_ds = load_my_dataset(splits=[\"test\"], SPLITS={'test':'data/bq_corpus/test.tsv'})\n",
    "tsv_name = 'bq_corpus.tsv'\n",
    "\n",
    "write_tsv(tsv_name, test_ds, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## paws-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.BAIDUData'>\n",
      "train dataset length: 49129\n",
      "dev dataset length: 2000\n",
      "{'query': '1560年10月，他在巴黎秘密会见了英国大使Nicolas Throckmorton，要求他通过苏格兰返回英国。', 'title': '1560年10月，他在巴黎秘密会见了英国大使尼古拉斯·斯罗克莫顿，并要求他通过英格兰返回苏格兰的护照。', 'label': 0}\n",
      "{'query': '1975年的NBA赛季 -  76赛季是全美篮球协会的第30个赛季。', 'title': '1975-76赛季的全国篮球协会是NBA的第30个赛季。', 'label': 1}\n",
      "{'query': '还有具体的讨论，公众形象辩论和项目讨论。', 'title': '还有公开讨论，特定档案讨论和项目讨论。', 'label': 0}\n",
      "{'query': '当可以保持相当的流速时，结果很高。', 'title': '当可以保持可比较的流速时，结果很高。', 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-11 22:57:40,421] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/vocab.txt\n",
      "100%|██████████| 78/78 [00:00<00:00, 4909.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataloader length: 384\n",
      "dev dataloader length: 16\n"
     ]
    }
   ],
   "source": [
    "train_ds, dev_ds = load_my_dataset(splits=[\"train\", \"dev\"], SPLITS={'train':'data/paws-x-zh/train.tsv', 'dev':'data/paws-x-zh/dev.tsv'})\n",
    "print(\"train dataset length:\", len(train_ds))\n",
    "print(\"dev dataset length:\", len(dev_ds))\n",
    "\n",
    "tokenizer = paddlenlp.transformers.ErnieGramTokenizer.from_pretrained('ernie-gram-zh')\n",
    "\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512)\n",
    "\n",
    "batch_size = 128\n",
    "train_data_loader = create_dataloader(dataset=train_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='train',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "dev_data_loader = create_dataloader(dataset=dev_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='dev',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "print(\"train dataloader length:\", len(train_data_loader))\n",
    "print(\"dev dataloader length:\", len(dev_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-11 22:58:29,048] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "model = PointwiseMatching(pretrained_model)\n",
    "state_dict = paddle.load(\"checkpoint_paws-x-zh_1/best_model_state.pdparams\")\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "epochs = 20\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate=5E-5, total_steps=num_training_steps, warmup=0.1)\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=0.0,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.74482, accu: 0.46719, lr: 0.0000006, speed: 1.18 step/s\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.70080, accu: 0.47578, lr: 0.0000012, speed: 1.23 step/s\n"
     ]
    }
   ],
   "source": [
    "from visualdl import LogWriter\n",
    "writer = LogWriter(\"./log_paws-x-zh_1\")\n",
    "save_dir = \"checkpoint_paws-x-zh_1\"\n",
    "\n",
    "train_model(model, optimizer, epochs, criterion, metric, save_dir, tokenizer, loader_list=[train_data_loader, dev_data_loader], patience=patience, lr_scheduler=lr_scheduler, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-11 17:47:52,656] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/ernie_gram_zh.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-gram-zh\n",
      "[2021-06-11 17:47:52,708] [    INFO] - Downloading ernie_gram_zh.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/ernie_gram_zh.pdparams\n",
      "100%|██████████| 583566/583566 [00:13<00:00, 43994.79it/s]\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "model = PointwiseMatching(pretrained_model)\n",
    "state_dict = paddle.load(\"checkpoint_paws-x-zh/best_model_state.pdparams\")\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.BAIDUData'>\n",
      "test_ds length 2000\n",
      "predict dataloader length: 16\n",
      "<class 'data.BAIDUData'>\n",
      "{'query': '2005 年末至 2009 年期间是例外，当时他效力于瑞典的卡斯塔德联队、塞尔维亚的查查克足球俱乐部和俄罗斯的格罗兹尼特里克足球俱乐部。', 'title': '例外情况发生于 2005 年末至 2009 年期间，当时他效力于瑞典的卡斯塔德联队、塞尔维亚的查查克足球俱乐部和俄罗斯的格罗兹尼艾卡马特足球俱乐部。', 'label': 1}\n",
      "{'query': 'Tabaci 河是罗马尼亚 Leurda 河的支流。', 'title': 'Leurda 河是罗马尼亚境内 Tabaci 河的一条支流。', 'label': 0}\n",
      "{'query': '1993 年，他为 A 级的坎恩郡美洲狮队和 AA 级的波特兰海狗队效力。', 'title': '1993 年，他为 A 级球队波特兰海狗队和 AA 级球队凯恩县美洲狮队效力。', 'label': 0}\n",
      "{'query': 'Winarsky 是 IEEE、Phi Beta Kappa、ACM 和 Sigma Xi 的成员。', 'title': '温那斯基是 ACM、IEEE、Phi Beta Kappa 和 Sigma Xi 的成员。', 'label': 1}\n",
      "{'query': '1938 年，他成为英埃苏丹的政府人类学家，并领导对努巴的实地考察工作。', 'title': '1938 年，他成为英埃苏丹政府的人类学家，并与努巴一起从事野外工作。', 'label': 1}\n",
      "{'query': '比利·比利·贝特森出现在 2008 年末至 2009 年初出版的前四期《黑亚当》中。', 'title': '黑亚当出现在 2008 年末至 2009 年初出版的前四期《比利·贝特森》中。', 'label': 0}\n",
      "{'query': '利用太阳能满足此项要求的方法是在常规动力飞机上使用太阳能板。', 'title': '利用太阳能满足此项要求的方法是在常规动力飞机上使用太阳能板。', 'label': 1}\n",
      "{'query': '在调查进行期间，警察还质询了歌手梨美·托米和演员卡薇雅·马德哈万，两人均为西迪基及其妻子迪利普的好友。', 'title': '作为持续进行的调查的一部分，警察还询问了歌手 Rimi Tomy 和演员 Kavya Madhavan，二人都是西迪基和他的妻子迪利普的好友。', 'label': 1}\n",
      "{'query': '它们被稀疏的现场管弦乐覆盖，并由模糊不清和几乎故意平淡的声音构成。', 'title': '它们被毫无音色的现场播放的音乐覆盖，并且由模糊不清、几乎故意稀疏的管弦乐声音构成。', 'label': 0}\n",
      "{'query': '霍利在音乐上受到了埃尔顿·约翰的影响。', 'title': '霍利 霍利在音乐上受到艾尔顿·约翰的影响。', 'label': 1}\n",
      "{'query': '球队在 2 月 19 日当晚对下一场比赛的变化作出了回应。', 'title': '该队在第二天（2 月 19 日）晚上的同一场比赛中应对变化。', 'label': 1}\n",
      "{'query': 'Nashua Silver Knights 队是当前夏季联赛的一部分，也是该市的大学体育队。', 'title': '纳舒厄白银骑士团队加入了夏季大学联盟，是本市的现役球队。', 'label': 0}\n",
      "{'query': '“断头台” 1949 年最后一次在西德使用，1966 年最后一次在东德使用。', 'title': '\"Fall Beil\" 于 1949 年最后一次在西德使用并于 1966 年在东德使用。', 'label': 1}\n",
      "{'query': '此运河为比利时，乃至欧洲，历史最为悠久的可通航运河之一。', 'title': '这条运河是比利时（确切来说是欧洲）最古老的通航运河之一。', 'label': 1}\n",
      "{'query': '他在 2009 年搬回了费城，现在住在纽约市。', 'title': '他于 2009 年搬回费城，现居住在纽约市。', 'label': 1}\n",
      "{'query': '1954 年 6 月 30 日，他因胃癌于俄克拉荷马州克莱摩尔病逝，而林恩·瑞格斯纪念馆则位于纽约市。', 'title': '1954 年 6 月 30 日，他因胃癌于纽约市病逝。而林恩·瑞格斯纪念馆则位于俄克拉荷马州克莱摩尔。', 'label': 0}\n",
      "{'query': '什蒂普西奇出生于德国科恩堡，在维也纳斯塔莫斯多夫度过了他的童年。', 'title': 'Stipsits 出生于科尔新堡，并在维也纳施塔莫斯多夫度过了他的童年。', 'label': 1}\n",
      "{'query': '凯塔王朝从 12 世纪至 17 世纪初一直统治着前帝国及帝国时期的马里。', 'title': '凯塔王朝在 12 世纪至 17 世纪统治了马里，在帝国成立前和帝国成立后都统治了。', 'label': 0}\n",
      "{'query': '“天使之眼”是 1946 年的一首流行歌曲，由马特·丹尼斯作曲，厄尔·布伦特作词。', 'title': '《Angel Eyes》是 1946 年的一首由 Earl Brent 作曲 Matt Dennis 作词的流行歌曲。', 'label': 0}\n",
      "{'query': '作曲人是茜娅姆，作词人是 Sreekumaran Thampi 和 Sathyan Anthikkad。', 'title': '音乐由希亚姆编写，歌词由斯列库伯兰·坦皮和 Sathyan Anthikkad 创作。', 'label': 1}\n",
      "{'query': '该影片在商业上取得巨大成功，也是塞尔乔·索利马较为成功的电影之一，且政治元素比该导演之前的意大利式西部片要少。', 'title': '该影片在商业上取得巨大成功，也是塞尔乔·索利马政治元素较多的电影之一，但不如该导演早期的意大利式西部片成功。', 'label': 0}\n",
      "{'query': '迦比尔要求莎莉卡揭露其终止兰威尔比赛的计划。', 'title': '卡比尔请求萨利卡向他透露结束兰维尔的游戏的计划。', 'label': 0}\n",
      "{'query': '团队回应了 2 月 19 日同一个晚上的下一场比赛的变化。', 'title': '团队回应了在第二年 2 月的晚上进行的同一场比赛中的变化。', 'label': 1}\n",
      "{'query': '中卫约翰·盖奇在 1805 年 5 月为北海使用了它们，中尉罗伯特·拉姆齐在 1806 年取代了他。', 'title': '1805 年 5 月，罗伯特·拉姆齐中尉将她派往北海，约翰·盖奇中尉于 1806 年接替了他。', 'label': 0}\n",
      "{'query': '艾玛·汤森德由 DGA Associates 的大卫·戈德温代表。', 'title': '艾玛·汤森是大卫·戈德温在 DGA Associates 的代表。', 'label': 1}\n",
      "{'query': '纳舒厄白银骑士队属于夏季大学联盟，目前是该市的球队。', 'title': 'Nashua Silver Knights 参加了本届夏季联赛，是该市的大学球队。', 'label': 0}\n",
      "{'query': '从大桥的西端开始，宾夕法尼亚州 268 号公路往南延伸至帕克，往北与埃姆伦顿相接。', 'title': '268 号宾夕法尼亚大道从帕克以南的大桥西端向北延伸至埃姆伦顿。', 'label': 1}\n",
      "{'query': '这些在英国十分常见，但在欧洲其他地方相对少见，至少对于大型铁路机车来说是如此。', 'title': '这在英国很罕见，但在欧洲，至少对于大型机车来说，它们相对常见。', 'label': 0}\n",
      "{'query': '阿尔斯通于 1965 年 12 月 21 日出生在马里兰州奥克森山。他就读于康涅狄格州纽黑文市的奥克森山高中。', 'title': '他于 1965 年 12 月 21 日出生于马里兰州奥克森山，并在康涅狄格州纽黑文上高中。', 'label': 1}\n",
      "{'query': '美国总伤亡人数为 28 人，而越共的损失为 345 人死亡，另有 192 人估计死亡。', 'title': '共有 28 名美国受害人遇害，而越南南方民族解放阵线遇害人数为 345 人，估计另有 192 人死亡。', 'label': 1}\n",
      "{'query': '在 CA，特许会计师的头衔（斯里兰卡斯里兰卡）只能由斯里兰卡会计师学会的成员使用。', 'title': '在 CA，特许会计师的职称（斯里兰卡斯里兰卡）仅限斯里兰卡特许会计师协会会员使用。', 'label': 1}\n",
      "{'query': '在于 3 月 14 日收购了 E-Plus 剩余的股份后，Simyo 属于荷兰电信集团 KPN。', 'title': '在 3 月 14 日收购 E-Plus 的剩余部分后，Simyo 属于荷兰电信集团 KPN。', 'label': 1}\n",
      "{'query': '除凯肯德尔外，罗伯特·怀特和约书亚·苏尔·齐默尔曼也担任了汉普夏县的档案馆专员。', 'title': '罗伯特·怀特和乔舒亚·索尔·齐默曼在旁协助担任汉普夏郡大法官法庭专员的库金德尔。', 'label': 0}\n",
      "{'query': '新教派、清教派和福音派的运动兴起期间经常有人表达这种观点。', 'title': '福音派、清教派和新教派的运动兴起期间经常有人表达这种观点。', 'label': 1}\n",
      "{'query': '费耶诺德鹿特丹队以 4 : 2 击败托特纳姆热刺足球俱乐部，从而赢得了 1973-74 欧洲联盟杯。', 'title': '在 1973 年至 1974 年的欧足联欧洲联赛上，费耶诺德鹿特丹队以 4 比 2 的总比分战胜了托特纳姆热刺队。', 'label': 1}\n",
      "{'query': '塔尔福尔德·伊利是克拉布·罗宾逊早期好友约翰·陶威尔·拉特的孙子。', 'title': '塔尔福尔德·伊利是克拉布·鲁滨逊的孙子，后者是约翰·陶威尔·拉特早年的一位朋友。', 'label': 1}\n",
      "{'query': '他的父亲在他年少时就去世了，他的母亲塞缪尔·亚当斯于 1842 年嫁给凯瑟琳·A·费根，后者两年后成为阿肯色州州长。', 'title': '他的父亲在他年少时去世了，而他的母亲凯瑟琳·A·费根于 1842 年嫁给塞缪尔·亚当斯， 后者在两年后成为阿肯色州州长。', 'label': 0}\n",
      "{'query': '他们还发行了专辑《Vices》的第 2 首歌曲，作为 6 月 13 日发行的专辑第五首单曲。', 'title': '他们还于 6 月 13 日发行了专辑《Vices》的第二首歌曲，作为该专辑的第五首单曲。', 'label': 1}\n",
      "{'query': '悉尼水务局于 1888 年从市议会手上接管了悉尼的供水。', 'title': '1888 年，悉尼水务局从市议会那里接管了悉尼供水事务。', 'label': 1}\n",
      "{'query': '蔡讽还有一个儿子，叫蔡瑁。', 'title': 'Cai Mao 也有一个儿子，他叫 Cai Feng。', 'label': 1}\n",
      "{'query': 'NS', 'title': '它的叶子沿着树枝交替排列，呈长矛状、卵状或几乎呈圆形，而且有长茎。', 'label': 0}\n",
      "{'query': '这扩大了马萨诸塞州和罗德岛省之间的冲突地区。', 'title': '这扩大了罗德岛和马萨诸塞省之间的冲突地区。', 'label': 1}\n",
      "{'query': '斯劳高中是伯克郡的一所精英女子语法学校，现在位于白金汉郡的斯劳。', 'title': '斯劳中学是一所位于白金汉郡斯劳（现在为伯克郡）的女子精英学校。', 'label': 0}\n",
      "{'query': '它邻近 Lough Corrib，位于康尼马拉的通往 Oughterard 和 Clifden 的 N59 公路。', 'title': '它距离奥格特拉德和克里夫登不远，位于康尼马拉前往科里布湖方向的 N59 号公路上的。', 'label': 0}\n",
      "{'query': '虽然排除黑人球员并非一项书面规定，但自 1933 年以来还没有非裔美国人曾为国家橄榄球联盟效力。', 'title': '虽然排除非洲球员并非明文规定，但是自 1933 年以来国家橄榄球联盟中没有任何非洲裔美国球员上场踢球。', 'label': 1}\n",
      "{'query': '在阿里死后，穆阿维耶上台执政，建立了一个王朝。', 'title': '在穆阿威亚逝世后，阿里掌权并建立王朝。', 'label': 0}\n",
      "{'query': '1994 年，Rodrigo Leão 离开乐队开始单飞生涯，被卡洛斯·玛丽亚·特林达德（键盘合成手）所取代。', 'title': '1994 年，罗德里戈·里奥离开乐队单飞，由卡洛斯·玛利亚·特林达德（键盘合成器）替代。', 'label': 1}\n",
      "{'query': '1933 年，卡特尔写道，在所有的北欧人种中，“欧洲人种的智力发育水平最高，性情最为稳定”。', 'title': '卡特尔在 1933 年写道，在北欧的所有人种中，“欧洲人种的智力发育水平最高，性情最为平稳”。', 'label': 1}\n",
      "{'query': '亚高山冷杉通常被称为北美西部冷杉或落基山冷杉，是一种亚高山带的冷杉树。', 'title': '落蒺山冷杉通常被称为北美西部枞树或落基山冷杉，是一种亚高山冷杉。', 'label': 0}\n",
      "{'query': '美国汽车公司仅以有限援助的形式提供技术支持。', 'title': 'American Motors 仅以有限帮助的形式提供技术支持。', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512,\n",
    "    is_test=True)\n",
    "    \n",
    "test_ds = load_my_dataset(splits=[\"test\"], SPLITS={'test':'data/paws-x-zh/test.tsv'})\n",
    "print('test_ds length', len(test_ds))\n",
    "\n",
    "predict_data_loader = create_dataloader(dataset=test_ds,\n",
    "                        trans_fn=trans_func,\n",
    "                        mode='test',\n",
    "                        batch_size=batch_size,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "print(\"predict dataloader length:\", len(predict_data_loader))\n",
    "\n",
    "y_probs = predict(model, predict_data_loader)\n",
    "\n",
    "y_preds = np.argmax(y_probs, axis=1)\n",
    "\n",
    "test_ds = load_my_dataset(splits=[\"test\"], SPLITS={'test':'data/paws-x-zh/test.tsv'})\n",
    "tsv_name = 'paws-x.tsv'\n",
    "write_tsv(tsv_name, test_ds, y_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
